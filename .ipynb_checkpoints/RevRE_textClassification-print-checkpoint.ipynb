{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2293c832",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kevalshah90/token-classification-fine-tuning/blob/main/RevRE_textClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79955bab",
   "metadata": {
    "id": "79955bab"
   },
   "source": [
    "### Fine-tuning an LLMs for Real Estate Financial statements text classification task\n",
    "\n",
    "\n",
    "Problem statement:\n",
    "\n",
    "A T12 is a financial statement that breaks down income and expenses of the real estate property over the past twelve months. Each line item is categorized as either income or expense. These reports can typically be obtained from PMSs (Property Management systems). Different PMSs may use slightly different structure / reporting formats. Thus, semantically similar line items may be worded differently. Additionally, T12s could also include multi-level hierarchy which has useful information. This makes it challenging to create standardized reporting across different systems.\n",
    "\n",
    "Proposed solution:\n",
    "\n",
    "Depending on the required complexity, availability of data and considerations for compute costs, we outline 3 different approaches (ordered by complexity). Each of them have some pros and cons:\n",
    "\n",
    "1. Train a ML classifier (eg. Random forest classifier)\n",
    "2. BERT\n",
    "3. LLMs (eg. llama)\n",
    "\n",
    "\n",
    "We have already trained a random forest classifier and have experimented with different parameters to improve accuracy. The **advantages** of BERT/LLMs for classification task is BERT and similar transformers-based LLMs excel at understanding the context and nuances of language, which can significantly improve classification accuracy, especially with complex or ambiguous text data. These models can better handle variations in language and new, unseen data due to their pre-training on large corpora.\n",
    "\n",
    "Architecture: \n",
    "\n",
    "BERT is trained using a masked language model (MLM) objective, where it predicts missing words in a sentence based on both left and right context. This bidirectional approach allows BERT to capture deeper contextual understanding compared to unidirectional models.\n",
    "\n",
    "In contrast, LLMs like GPT generate text by predicting the next token in a sequence based on preceding context, focusing on generating coherent and contextually appropriate text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a87eb8",
   "metadata": {},
   "source": [
    "Let's start with **BERT**\n",
    "\n",
    "**BERT** relies on a Transformer (the attention mechanism that learns contextual relationships between words in a text). A basic Transformer consists of an encoder to read the text input and a decoder to produce a prediction for the task. Since BERTâ€™s goal is to generate a language representation model, it only needs the encoder part. The input to the encoder for BERT is a sequence of tokens, which are first converted into vectors and then processed in the neural network. But before processing can start, BERT needs the input to be massaged and decorated with some extra metadata:\n",
    "\n",
    "Token embeddings: A [CLS] token is added to the input word tokens at the beginning of the first sentence and a [SEP] token is inserted at the end of each sentence.\n",
    "Segment embeddings: A marker indicating Sentence A or Sentence B is added to each token. This allows the encoder to distinguish between sentences.\n",
    "Positional embeddings: A positional embedding is added to each token to indicate its position in the sentence.\n",
    "\n",
    "BERT seems like a good option for text classification given that it is trained on general text data corpus and may capture the context from the hierarchical structure. Since, our goal is text classification BERTs encoder-only architecture would work well for us. Depending on different evaluation metrics from BERT, we can decide if LLMs are worth a shot.\n",
    "\n",
    "- https://arxiv.org/abs/1810.04805\n",
    "\n",
    "- https://github.com/google-research/bert\n",
    "\n",
    "- https://osanseviero.github.io/hackerllama/blog/posts/random_transformer/\n",
    "\n",
    "- https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\n",
    "\n",
    "- https://towardsdatascience.com/text-classification-with-bert-in-pytorch-887965e5820f\n",
    "\n",
    "- https://github.com/huggingface/blog/blob/main/Lora-for-sequence-classification-with-Roberta-Llama-Mistral.md\n",
    "\n",
    "- https://github.com/rasbt/LLMs-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb\n",
    "\n",
    "- https://www.kaggle.com/code/neerajmohan/fine-tuning-bert-for-text-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf4d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Jun 21 20:23:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   33C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# check hardware\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6661b06e",
   "metadata": {},
   "source": [
    "**Hardware**\n",
    "\n",
    "`ml.g4dn.xlarge instance, T4 (Turing Architecture)`\n",
    "\n",
    "- CUDA Cores: 2,560\n",
    "- Tensor Cores: 320 (2nd gen)\n",
    "- Memory: 16GB GDDR6\n",
    "- Memory Bandwidth: 300 GB/s\n",
    "- TDP: 70W\n",
    "- FP32 Performance: 8.1 TFLOPS\n",
    "- FP16 Performance: 65 TFLOPS\n",
    "- INT8 Performance: 130 TOPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca6cc7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/token-classification-fine-tuning'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "138f95be",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = !ls\n",
    "#files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf6b121",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "if 'requirements.txt' in files:\n",
    "    !pip install -r requirements.txt #--extra-index-url https://pypi.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8299077",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install --upgrade accelerate==0.29.0\n",
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efe626e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\r\n",
      "----------------------------- -------------------\r\n",
      "accelerate                    0.31.0\r\n",
      "aiohttp                       3.9.3\r\n",
      "aiosignal                     1.3.1\r\n",
      "alabaster                     0.7.16\r\n",
      "annotated-types               0.7.0\r\n",
      "anyio                         4.3.0\r\n",
      "argon2-cffi                   23.1.0\r\n",
      "argon2-cffi-bindings          21.2.0\r\n",
      "arrow                         1.3.0\r\n",
      "astroid                       2.15.8\r\n",
      "astropy                       6.0.0\r\n",
      "astropy-iers-data             0.2024.3.25.0.29.50\r\n",
      "asttokens                     2.4.1\r\n",
      "async-lru                     2.0.4\r\n",
      "async-timeout                 4.0.3\r\n",
      "atomicwrites                  1.4.1\r\n",
      "attrs                         23.2.0\r\n",
      "autopep8                      2.0.4\r\n",
      "autovizwidget                 0.21.0\r\n",
      "awscli                        1.32.101\r\n",
      "Babel                         2.14.0\r\n",
      "beautifulsoup4                4.12.3\r\n",
      "binaryornot                   0.4.4\r\n",
      "bitarray                      2.9.2\r\n",
      "bitsandbytes                  0.43.1\r\n",
      "black                         24.3.0\r\n",
      "bleach                        6.1.0\r\n",
      "blinker                       1.7.0\r\n",
      "blis                          0.7.11\r\n",
      "bokeh                         3.4.0\r\n",
      "boto3                         1.34.101\r\n",
      "botocore                      1.34.101\r\n",
      "Bottleneck                    1.3.8\r\n",
      "Brotli                        1.1.0\r\n",
      "brotlipy                      0.7.0\r\n",
      "cached-property               1.5.2\r\n",
      "catalogue                     2.0.10\r\n",
      "certifi                       2024.2.2\r\n",
      "cffi                          1.16.0\r\n",
      "chardet                       5.2.0\r\n",
      "charset-normalizer            3.3.2\r\n",
      "click                         8.1.7\r\n",
      "cloudpathlib                  0.18.1\r\n",
      "cloudpickle                   2.2.1\r\n",
      "colorama                      0.4.6\r\n",
      "comm                          0.2.2\r\n",
      "confection                    0.1.5\r\n",
      "contourpy                     1.2.0\r\n",
      "cookiecutter                  2.6.0\r\n",
      "coverage                      7.4.4\r\n",
      "cryptography                  42.0.5\r\n",
      "cycler                        0.12.1\r\n",
      "cymem                         2.0.8\r\n",
      "Cython                        3.0.9\r\n",
      "cytoolz                       0.12.3\r\n",
      "dask                          2024.3.1\r\n",
      "dask-expr                     1.0.5\r\n",
      "datasets                      2.20.0\r\n",
      "debugpy                       1.8.1\r\n",
      "decorator                     5.1.1\r\n",
      "defusedxml                    0.7.1\r\n",
      "diff-match-patch              20230430\r\n",
      "dill                          0.3.8\r\n",
      "distributed                   2024.3.1\r\n",
      "docker                        6.1.3\r\n",
      "docstring-to-markdown         0.15\r\n",
      "docutils                      0.16\r\n",
      "dparse                        0.6.3\r\n",
      "entrypoints                   0.4\r\n",
      "et-xmlfile                    1.1.0\r\n",
      "exceptiongroup                1.2.0\r\n",
      "executing                     2.0.1\r\n",
      "fastcache                     1.1.0\r\n",
      "fastjsonschema                2.19.1\r\n",
      "filelock                      3.13.3\r\n",
      "flake8                        6.0.0\r\n",
      "Flask                         3.0.2\r\n",
      "Flask-Cors                    4.0.0\r\n",
      "fonttools                     4.50.0\r\n",
      "fqdn                          1.5.1\r\n",
      "frozenlist                    1.4.1\r\n",
      "fsspec                        2024.3.1\r\n",
      "future                        1.0.0\r\n",
      "gevent                        23.9.0.post1\r\n",
      "gmpy2                         2.1.2\r\n",
      "google-pasta                  0.2.0\r\n",
      "greenlet                      3.0.3\r\n",
      "gssapi                        1.8.3\r\n",
      "h11                           0.14.0\r\n",
      "h2                            4.1.0\r\n",
      "h5py                          3.10.0\r\n",
      "hdijupyterutils               0.21.0\r\n",
      "hpack                         4.0.0\r\n",
      "httpcore                      1.0.4\r\n",
      "httpx                         0.27.0\r\n",
      "huggingface-hub               0.23.4\r\n",
      "hyperframe                    6.0.1\r\n",
      "idna                          3.6\r\n",
      "imagecodecs                   2024.1.1\r\n",
      "imageio                       2.34.0\r\n",
      "imagesize                     1.4.1\r\n",
      "immutables                    0.20\r\n",
      "importlib-metadata            6.11.0\r\n",
      "importlib_resources           6.4.0\r\n",
      "inflection                    0.5.1\r\n",
      "iniconfig                     2.0.0\r\n",
      "intervaltree                  3.1.0\r\n",
      "ipykernel                     6.29.3\r\n",
      "ipython                       8.22.2\r\n",
      "ipython-genutils              0.2.0\r\n",
      "ipywidgets                    8.1.2\r\n",
      "isoduration                   20.11.0\r\n",
      "isort                         5.13.2\r\n",
      "itsdangerous                  2.1.2\r\n",
      "jaraco.classes                3.3.1\r\n",
      "jaraco.context                4.3.0\r\n",
      "jaraco.functools              4.0.0\r\n",
      "jedi                          0.18.2\r\n",
      "jeepney                       0.8.0\r\n",
      "jellyfish                     1.0.3\r\n",
      "Jinja2                        3.1.3\r\n",
      "jmespath                      1.0.1\r\n",
      "joblib                        1.3.2\r\n",
      "json5                         0.9.24\r\n",
      "jsonpointer                   2.4\r\n",
      "jsonschema                    4.21.1\r\n",
      "jsonschema-specifications     2023.12.1\r\n",
      "jupyter                       1.0.0\r\n",
      "jupyter_client                8.6.1\r\n",
      "jupyter-console               6.6.3\r\n",
      "jupyter_core                  5.7.2\r\n",
      "jupyter-events                0.10.0\r\n",
      "jupyter-lsp                   2.2.4\r\n",
      "jupyter_server                2.13.0\r\n",
      "jupyter_server_terminals      0.5.3\r\n",
      "jupyterlab                    4.1.5\r\n",
      "jupyterlab_pygments           0.3.0\r\n",
      "jupyterlab_server             2.25.4\r\n",
      "jupyterlab_widgets            3.0.10\r\n",
      "keyring                       25.0.0\r\n",
      "kiwisolver                    1.4.5\r\n",
      "krb5                          0.5.1\r\n",
      "langcodes                     3.4.0\r\n",
      "language_data                 1.2.0\r\n",
      "lazy_loader                   0.3\r\n",
      "lazy-object-proxy             1.10.0\r\n",
      "llvmlite                      0.42.0\r\n",
      "locket                        1.0.0\r\n",
      "lz4                           4.3.3\r\n",
      "marisa-trie                   1.2.0\r\n",
      "markdown-it-py                3.0.0\r\n",
      "MarkupSafe                    2.1.5\r\n",
      "matplotlib                    3.8.3\r\n",
      "matplotlib-inline             0.1.6\r\n",
      "mccabe                        0.7.0\r\n",
      "mdurl                         0.1.2\r\n",
      "mistune                       3.0.2\r\n",
      "mkl_fft                       1.3.8\r\n",
      "mkl-service                   2.4.1\r\n",
      "mock                          5.1.0\r\n",
      "more-itertools                10.2.0\r\n",
      "mpmath                        1.3.0\r\n",
      "msgpack                       1.0.7\r\n",
      "multidict                     6.0.5\r\n",
      "multiprocess                  0.70.16\r\n",
      "munkres                       1.1.4\r\n",
      "murmurhash                    1.0.10\r\n",
      "mypy-extensions               1.0.0\r\n",
      "nbclient                      0.10.0\r\n",
      "nbconvert                     7.16.3\r\n",
      "nbformat                      5.10.3\r\n",
      "nest_asyncio                  1.6.0\r\n",
      "networkx                      3.2.1\r\n",
      "nltk                          3.8.1\r\n",
      "nose                          1.3.7\r\n",
      "notebook                      7.1.2\r\n",
      "notebook_shim                 0.2.4\r\n",
      "numba                         0.59.1\r\n",
      "numexpr                       2.9.0\r\n",
      "numpy                         1.22.4\r\n",
      "numpydoc                      1.6.0\r\n",
      "nvidia-cublas-cu12            12.1.3.1\r\n",
      "nvidia-cuda-cupti-cu12        12.1.105\r\n",
      "nvidia-cuda-nvrtc-cu12        12.1.105\r\n",
      "nvidia-cuda-runtime-cu12      12.1.105\r\n",
      "nvidia-cudnn-cu12             8.9.2.26\r\n",
      "nvidia-cufft-cu12             11.0.2.54\r\n",
      "nvidia-curand-cu12            10.3.2.106\r\n",
      "nvidia-cusolver-cu12          11.4.5.107\r\n",
      "nvidia-cusparse-cu12          12.1.0.106\r\n",
      "nvidia-nccl-cu12              2.20.5\r\n",
      "nvidia-nvjitlink-cu12         12.5.40\r\n",
      "nvidia-nvtx-cu12              12.1.105\r\n",
      "openpyxl                      3.1.2\r\n",
      "overrides                     7.7.0\r\n",
      "packaging                     21.3\r\n",
      "pandas                        2.2.1\r\n",
      "pandocfilters                 1.5.0\r\n",
      "parso                         0.8.3\r\n",
      "partd                         1.4.1\r\n",
      "path                          16.10.0\r\n",
      "pathlib2                      2.3.7.post1\r\n",
      "pathos                        0.3.2\r\n",
      "pathspec                      0.12.1\r\n",
      "patsy                         0.5.6\r\n",
      "peft                          0.11.1\r\n",
      "pexpect                       4.9.0\r\n",
      "pickleshare                   0.7.5\r\n",
      "pillow                        10.2.0\r\n",
      "pip                           23.3.2\r\n",
      "pkginfo                       1.10.0\r\n",
      "pkgutil_resolve_name          1.3.10\r\n",
      "platformdirs                  4.2.0\r\n",
      "plotly                        5.19.0\r\n",
      "pluggy                        1.4.0\r\n",
      "ply                           3.11\r\n",
      "pox                           0.3.4\r\n",
      "ppft                          1.7.6.8\r\n",
      "preshed                       3.0.9\r\n",
      "prometheus_client             0.20.0\r\n",
      "prompt-toolkit                3.0.42\r\n",
      "protobuf                      4.25.3\r\n",
      "psutil                        5.9.8\r\n",
      "psycopg2                      2.9.9\r\n",
      "psycopg2-binary               2.9.9\r\n",
      "ptyprocess                    0.7.0\r\n",
      "pure-eval                     0.2.2\r\n",
      "py-cpuinfo                    9.0.0\r\n",
      "py4j                          0.10.9.5\r\n",
      "pyarrow                       15.0.2\r\n",
      "pyarrow-hotfix                0.6\r\n",
      "pyasn1                        0.6.0\r\n",
      "pycodestyle                   2.10.0\r\n",
      "pycosat                       0.6.6\r\n",
      "pycparser                     2.21\r\n",
      "pycryptodome                  3.20.0\r\n",
      "pycurl                        7.45.3\r\n",
      "pydantic                      2.7.4\r\n",
      "pydantic_core                 2.18.4\r\n",
      "pydocstyle                    6.3.0\r\n",
      "pyerfa                        2.0.1.1\r\n",
      "pyflakes                      3.0.1\r\n",
      "Pygments                      2.17.2\r\n",
      "pykerberos                    1.2.4\r\n",
      "pylint                        2.17.7\r\n",
      "pylint-venv                   3.0.3\r\n",
      "pyls-spyder                   0.4.0\r\n",
      "pynvml                        11.5.0\r\n",
      "pyodbc                        5.1.0\r\n",
      "pyOpenSSL                     24.0.0\r\n",
      "pyparsing                     3.1.2\r\n",
      "PyQt5                         5.15.9\r\n",
      "PyQt5-sip                     12.12.2\r\n",
      "PyQtWebEngine                 5.15.4\r\n",
      "pyrsistent                    0.20.0\r\n",
      "PySocks                       1.7.1\r\n",
      "pyspark                       3.3.0\r\n",
      "pyspnego                      0.9.1\r\n",
      "pytest                        8.1.1\r\n",
      "python-dateutil               2.9.0\r\n",
      "python-dotenv                 1.0.1\r\n",
      "python-json-logger            2.0.7\r\n",
      "python-lsp-black              2.0.0\r\n",
      "python-lsp-jsonrpc            1.1.2\r\n",
      "python-lsp-server             1.7.4\r\n",
      "python-slugify                8.0.4\r\n",
      "pytoolconfig                  1.2.5\r\n",
      "pytz                          2024.1\r\n",
      "PyWavelets                    1.4.1\r\n",
      "pyxdg                         0.28\r\n",
      "PyYAML                        6.0.1\r\n",
      "pyzmq                         25.1.2\r\n",
      "QDarkStyle                    3.1\r\n",
      "qstylizer                     0.2.2\r\n",
      "QtAwesome                     1.3.0\r\n",
      "qtconsole                     5.4.4\r\n",
      "QtPy                          2.4.1\r\n",
      "referencing                   0.34.0\r\n",
      "regex                         2023.12.25\r\n",
      "requests                      2.32.3\r\n",
      "requests-kerberos             0.14.0\r\n",
      "rfc3339-validator             0.1.4\r\n",
      "rfc3986-validator             0.1.1\r\n",
      "rich                          13.7.1\r\n",
      "rope                          1.13.0\r\n",
      "rpds-py                       0.18.0\r\n",
      "rsa                           4.7.2\r\n",
      "Rtree                         1.2.0\r\n",
      "ruamel.yaml                   0.18.6\r\n",
      "ruamel.yaml.clib              0.2.8\r\n",
      "ruamel-yaml-conda             0.15.80\r\n",
      "s3fs                          0.4.2\r\n",
      "s3transfer                    0.10.1\r\n",
      "safetensors                   0.4.3\r\n",
      "sagemaker                     2.219.0\r\n",
      "sagemaker_pyspark             1.4.5\r\n",
      "schema                        0.7.7\r\n",
      "scikit-image                  0.22.0\r\n",
      "scikit-learn                  1.4.1.post1\r\n",
      "scipy                         1.12.0\r\n",
      "seaborn                       0.13.2\r\n",
      "SecretStorage                 3.3.3\r\n",
      "Send2Trash                    1.8.2\r\n",
      "setuptools                    69.2.0\r\n",
      "shap                          0.45.0\r\n",
      "shellingham                   1.5.4\r\n",
      "sip                           6.7.12\r\n",
      "six                           1.16.0\r\n",
      "slicer                        0.0.7\r\n",
      "smart-open                    7.0.4\r\n",
      "smdebug-rulesconfig           1.0.1\r\n",
      "sniffio                       1.3.1\r\n",
      "snowballstemmer               2.2.0\r\n",
      "sortedcontainers              2.4.0\r\n",
      "soupsieve                     2.5\r\n",
      "spacy                         3.7.5\r\n",
      "spacy_annotator               2.1.4\r\n",
      "spacy-legacy                  3.0.12\r\n",
      "spacy-loggers                 1.0.5\r\n",
      "sparkmagic                    0.21.0\r\n",
      "Sphinx                        7.2.6\r\n",
      "sphinxcontrib-applehelp       1.0.8\r\n",
      "sphinxcontrib-devhelp         1.0.6\r\n",
      "sphinxcontrib-htmlhelp        2.0.5\r\n",
      "sphinxcontrib-jsmath          1.0.1\r\n",
      "sphinxcontrib-qthelp          1.0.7\r\n",
      "sphinxcontrib-serializinghtml 1.1.10\r\n",
      "sphinxcontrib-websupport      1.2.7\r\n",
      "spyder                        5.4.5\r\n",
      "spyder-kernels                2.4.4\r\n",
      "SQLAlchemy                    2.0.29\r\n",
      "srsly                         2.4.8\r\n",
      "stack-data                    0.6.2\r\n",
      "statsmodels                   0.14.1\r\n",
      "sympy                         1.12\r\n",
      "tables                        3.9.2\r\n",
      "tabulate                      0.9.0\r\n",
      "tblib                         3.0.0\r\n",
      "tenacity                      8.2.3\r\n",
      "terminado                     0.18.1\r\n",
      "testpath                      0.6.0\r\n",
      "text-unidecode                1.3\r\n",
      "textdistance                  4.5.0\r\n",
      "thinc                         8.2.5\r\n",
      "threadpoolctl                 3.4.0\r\n",
      "three-merge                   0.1.1\r\n",
      "tifffile                      2024.2.12\r\n",
      "tinycss2                      1.2.1\r\n",
      "tokenizers                    0.19.1\r\n",
      "toml                          0.10.2\r\n",
      "tomli                         2.0.1\r\n",
      "tomlkit                       0.12.4\r\n",
      "toolz                         0.12.1\r\n",
      "torch                         2.3.1\r\n",
      "tornado                       6.4\r\n",
      "tqdm                          4.66.4\r\n",
      "traitlets                     5.14.2\r\n",
      "transformers                  4.41.2\r\n",
      "triton                        2.3.1\r\n",
      "typed-ast                     1.5.5\r\n",
      "typer                         0.12.3\r\n",
      "types-python-dateutil         2.9.0.20240316\r\n",
      "typing_extensions             4.10.0\r\n",
      "typing-utils                  0.1.0\r\n",
      "tzdata                        2024.1\r\n",
      "ujson                         5.9.0\r\n",
      "unicodedata2                  15.1.0\r\n",
      "uri-template                  1.3.0\r\n",
      "urllib3                       2.2.1\r\n",
      "wasabi                        1.1.3\r\n",
      "watchdog                      4.0.0\r\n",
      "wcwidth                       0.2.13\r\n",
      "weasel                        0.4.1\r\n",
      "webcolors                     1.13\r\n",
      "webencodings                  0.5.1\r\n",
      "websocket-client              1.7.0\r\n",
      "Werkzeug                      3.0.1\r\n",
      "whatthepatch                  1.0.5\r\n",
      "wheel                         0.43.0\r\n",
      "widgetsnbextension            4.0.10\r\n",
      "wrapt                         1.16.0\r\n",
      "wurlitzer                     3.0.3\r\n",
      "XlsxWriter                    3.1.9\r\n",
      "xxhash                        3.4.1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xyzservices                   2023.10.1\r\n",
      "yapf                          0.40.1\r\n",
      "yarl                          1.9.4\r\n",
      "zict                          3.0.0\r\n",
      "zipp                          3.17.0\r\n",
      "zope.event                    5.0\r\n",
      "zope.interface                6.2\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ff8a0c2",
   "metadata": {
    "id": "0ff8a0c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, BertTokenizer, BertModel, BertConfig, DistilBertTokenizer, \\\n",
    "DistilBertModel, pipeline, BitsAndBytesConfig, DataCollatorWithPadding, AutoModelForSequenceClassification, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, get_peft_model_state_dict\n",
    "from datasets import load_dataset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# NER Annotation\n",
    "import spacy\n",
    "import spacy_annotator as spacy_anot\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf8a786e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print environ variables\n",
    "os.environ['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce50a69d",
   "metadata": {
    "id": "ce50a69d",
    "outputId": "80cdcf54-cec2-4d7a-8601-f97b23de46c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Setting up the device for GPU usage\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b81d998d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda version: 12.1\n"
     ]
    }
   ],
   "source": [
    "print(f\"cuda version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5414213",
   "metadata": {
    "id": "a5414213",
    "outputId": "a4bdf002-7f61-41ae-a501-f07bf72cf3b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2234, 18)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv\n",
    "df = pd.read_csv(\"output1.csv\", on_bad_lines=\"skip\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6e72dbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header</th>\n",
       "      <th>INCOME</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>Less: Technology Allocation</td>\n",
       "      <td>JOB - Tech Package</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Less: Marketing</td>\n",
       "      <td>Resident Good Will</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>Less: Parking Maintenance</td>\n",
       "      <td>Parking Lot Repair</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Less: Concessions</td>\n",
       "      <td>Concessions - Recurring</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>Total</td>\n",
       "      <td>GENERAL ADMINISTRATION</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Header                   INCOME   Income\n",
       "875   Less: Technology Allocation       JOB - Tech Package  Expense\n",
       "621               Less: Marketing       Resident Good Will  Expense\n",
       "275     Less: Parking Maintenance       Parking Lot Repair  Expense\n",
       "20              Less: Concessions  Concessions - Recurring   Income\n",
       "1879                        Total   GENERAL ADMINISTRATION  Expense"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Header','INCOME','Income']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcb5d3ee",
   "metadata": {
    "id": "fcb5d3ee",
    "outputId": "dfff9319-057b-40bd-f241-07324091a038"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>Less: Capital Improvements CAP- Environmental</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>Less: Office Expenses Copier Expense</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>Less: Parking Maintenance JOB - Garage</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1494</th>\n",
       "      <td>Less: Payroll Taxes &amp; Benefits Administrative ...</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Not Classified Gain/Loss on Sale</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texts    label\n",
       "721       Less: Capital Improvements CAP- Environmental  Expense\n",
       "1527               Less: Office Expenses Copier Expense  Expense\n",
       "868              Less: Parking Maintenance JOB - Garage  Expense\n",
       "1494  Less: Payroll Taxes & Benefits Administrative ...  Expense\n",
       "1181                   Not Classified Gain/Loss on Sale  Expense"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format data such that we have 2 columns text and label\n",
    "\n",
    "# By concatenating the two text fields into one column, we provide LLMs more nuanced understanding and context. \n",
    "df['texts'] = df['Header'] + \" \" + df['INCOME']\n",
    "df.rename(columns={'Income':'label'}, inplace=True)\n",
    "\n",
    "# subset dataframe with required columns only\n",
    "df1 = df[['texts','label']]\n",
    "df1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32bc61d3",
   "metadata": {
    "id": "32bc61d3",
    "outputId": "148cb4b1-2bf6-41b5-ab71-552648ce353b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7916/287641274.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.dropna(inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='label', ylabel='Count'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop NAs\n",
    "df1.dropna(inplace=True)\n",
    "sns.histplot(df1, x='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77ce957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "Expense    1500\n",
      "Income      508\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df1['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01317745",
   "metadata": {
    "id": "01317745",
    "outputId": "8c324db9-9ffa-491c-9a7f-253ace067b11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2008, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09ae566",
   "metadata": {},
   "source": [
    "**Synthetic data generation for Balanced Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae367c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the minority and majority classes\n",
    "minority_class = df1[df1['label'] == 'Income']\n",
    "majority_class = df1[df1['label'] == 'Expense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d46c008d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'minority samples :2492 and majority samples: 1500'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minority_samples_desired = 3000 - minority_class.shape[0]\n",
    "majority_samples_desired = 3000 - majority_class.shape[0]\n",
    "\n",
    "f\"minority samples :{minority_samples_desired} and majority samples: {majority_samples_desired}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c808042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsample the minority class\n",
    "upsampled_minority = resample(minority_class, replace=True, n_samples=minority_samples_desired, random_state=42)\n",
    "\n",
    "# Downsample the majority class\n",
    "downsampled_majority = resample(majority_class, replace=False, n_samples=majority_samples_desired, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4747da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Income     3000\n",
       "Expense    3000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Balanced data\n",
    "df2 = pd.concat([df1, upsampled_minority, downsampled_majority])\n",
    "df2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "473d0e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>Plus: Late Charges Legal</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>Plus: Utilities Income: Water Reimbursed Water</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>Less: Insurance Excess Liability Insurance</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Less: Interior Decorating Interior Painting</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Plus: Renter's Insurance Insurance Recovery - ...</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texts    label\n",
       "1943                           Plus: Late Charges Legal   Income\n",
       "1390     Plus: Utilities Income: Water Reimbursed Water   Income\n",
       "386          Less: Insurance Excess Liability Insurance  Expense\n",
       "276         Less: Interior Decorating Interior Painting  Expense\n",
       "87    Plus: Renter's Insurance Insurance Recovery - ...   Income"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9df276f",
   "metadata": {
    "id": "e9df276f"
   },
   "source": [
    "#### BERT Pre-Training: Tokenization\n",
    "\n",
    "As a first step, we need to transform this sentence into a sequence of tokens (words) and this process is called tokenization.\n",
    "\n",
    "BERT model expects a sequence of tokens (words) as an input. In each sequence of tokens, there are two special tokens that BERT would expect as an input:\n",
    "\n",
    "[CLS]: This is the first token of every sequence, which stands for classification token.\n",
    "\n",
    "[SEP]: This is the token that makes BERT know which token belongs to which sequence.\n",
    "\n",
    "BERT model then will output an embedding vector of size 768 in each of the tokens. We can use these vectors as an input for different kinds of NLP applications, whether it is text classification, next sentence prediction, Named-Entity-Recognition (NER), or question-answering.\n",
    "\n",
    "For a text classification task, we focus our attention on the embedding vector output from the special [CLS] token. This means that weâ€™re going to use the embedding vector of size 768 from [CLS] token as an input for our classifier, which then will output a vector of size the number of classes in our classification task.\n",
    "\n",
    "<img src=\"https://github.com/kevalshah90/token-classification-fine-tuning/blob/main/bert.png?raw=1\" width=\"500px\" height=\"500px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa2c68b",
   "metadata": {
    "id": "eaa2c68b"
   },
   "source": [
    "An Conceptual walk through of BERT:\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/09/an-explanatory-guide-to-bert-tokenizer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d82fff28",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "e615aa5d72da47639cf512920c2a9df1",
      "da715ea0f6da4bc697b024920b430ce9",
      "015f55cd9fcc49cebfa68d7aec6ecff1",
      "532b85d6b2c9456ca3249b12c9f10cda",
      "5081ab99d10d41b29b4d4ae53a6cb764"
     ]
    },
    "id": "d82fff28",
    "outputId": "bd4d1b19-5ee7-40c7-b142-dd190cc5a211",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98d875d117f44256b2410b02d264b7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f2e8beeefe440db514eba5bb0aa71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f21f2634f7e4ee08576b1bec89d429a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672719c9aab444d18dafbb5f47700411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0609dd7f7a144183bbd0daabbb106d36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw bert input: {'input_ids': tensor([[  101,  1045,  2097,  3422,  2033, 23065,  3892,   102,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])}\n"
     ]
    }
   ],
   "source": [
    "# Let's define a tokenizer and see how it works with example text, before applying it on our dataset\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Download model weights and configuration from huggingface.co and cache.\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# save model\n",
    "folder = '/home/ec2-user/SageMaker/token-classification-fine-tuning/model'\n",
    "model.save_pretrained(folder)\n",
    "tokenizer.save_pretrained(folder)\n",
    "\n",
    "# Load model from local directory\n",
    "model = BertModel.from_pretrained(folder)\n",
    "tokenizer = BertTokenizer.from_pretrained(folder)\n",
    "\n",
    "text = \"I will watch Memento tonight\"\n",
    "\n",
    "bert_input = tokenizer(\n",
    "                       text,\n",
    "                       padding='max_length',\n",
    "                       max_length = 10,\n",
    "                       truncation=True,\n",
    "                       return_tensors='pt'\n",
    "                      )\n",
    "\n",
    "print(f'raw bert input: {bert_input}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3deb1aab",
   "metadata": {
    "id": "3deb1aab"
   },
   "source": [
    "1. The first row is `input_ids`, which is the id representation of each token. We can actually decode these `input ids` into the actual tokens.\n",
    "\n",
    "2. The `attention mask` is used when batching sequences together. This indicates to the model which tokens should be attended to, and which should not. \n",
    "\n",
    "3. `token_type_ids` is used to distinguish between 2 input sequences. \n",
    "\n",
    "4. `positionIDs` are used by the model to identify which token is at which position. Contrary to RNNs that have the position of each token embedded within them, transformers are unaware of the position of each token. The position IDs are created for this purpose. They are an optional parameter. If no position IDs are passed to the model, they are automatically created as absolute positional embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a90f80f2",
   "metadata": {
    "id": "a90f80f2",
    "outputId": "4d5f3e55-fd45-4bb0-f031-16b3a4a3287b"
   },
   "outputs": [],
   "source": [
    "#decoded_text = tokenizer.decode(bert_input.input_ids[0])\n",
    "#print(decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53de81df",
   "metadata": {
    "id": "53de81df"
   },
   "source": [
    "The second row is the `attention_mask`, which is a binary mask that identifies whether a token is a real word or just padding. If the token contains [CLS], [SEP], or any real word, then the mask would be 1. Meanwhile, if the token is just padding or [PAD], then the mask would be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd0c2f9d",
   "metadata": {
    "id": "dd0c2f9d",
    "outputId": "a6b215f2-0391-4e3b-cf47-66a3dbdb9b3d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The double-asterisk syntax (**) is used for dictionary unpacking in Python.\n",
    "# For example, if inputs is {'input_ids': ..., 'attention_mask': ...}, then model(**inputs) is equivalent to model(input_ids=..., attention_mask=...).\n",
    "\n",
    "# Docs: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel\n",
    "#output = model(**bert_input)\n",
    "#print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1887d47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b39c063",
   "metadata": {},
   "source": [
    "**Bert model output**\n",
    "\n",
    "A contextualized embedding vector of `768`-dimension, typically the last hidden layer, generated for each token in the input sentence.\n",
    "\n",
    "BERT Embeddings: BERT builds upon pre-trained word embeddings, which capture the meaning of individual words. These word embeddings are typically much lower dimensional (e.g., 300).\n",
    "\n",
    "Contextualization: BERT goes beyond basic word embeddings by incorporating contextual information. It considers the entire sentence and the relationships between words using its encoder layers and attention mechanism.\n",
    "\n",
    "Higher Dimensionality: The 768 dimension in the contextualized embedding allows BERT to capture a richer and more nuanced representation of a word's meaning based on the surrounding context. This additional dimension compared to word embeddings enables BERT to model these complex contextual relationships.\n",
    "\n",
    "In summary,\n",
    "\n",
    "- Input Representation: Combines token, segment, and position embeddings.\n",
    "\n",
    "- Self-Attention: Allows each token to attend to all other tokens, capturing context.\n",
    "\n",
    "- Multi-Head Attention: Focuses on different parts of the sequence.\n",
    "\n",
    "- Feed-Forward Network: Applies transformations to enrich the representations.\n",
    "\n",
    "- Layer Normalization and Residual Connections: Stabilize and enhance training.\n",
    "\n",
    "- Stacked Layers: Deepen the contextual understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ceb138",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085c72b2",
   "metadata": {
    "id": "085c72b2"
   },
   "source": [
    "**Data pre-processing, Dataset and DataLoader from pytorch.data.utils**\n",
    "\n",
    "Let's write a class to tokenize our data and generate necessary outputs for the BERT model. This class defines how the text is pre-processed before sending it to the neural network.\n",
    "\n",
    "The *Dataset* and *DataLoader* classes provide a mechanism to load data efficiently in batches during training.\n",
    "\n",
    "pytorch allows for parallel processing using multiple CPU cores or GPUs. **DataLoader helps in parallelizing data** loading, enabling the model to process multiple batches simultaneously.\n",
    "\n",
    "The **Dataset class allows you to define custom transformations** on the input data, such as resizing images, normalizing pixel values, or tokenizing text. These transformations are applied on-the-fly during data loading.\n",
    "\n",
    "DataLoader handles the process of grouping samples into batches, making it easier to feed batches of data to the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "04307d5c",
   "metadata": {
    "id": "04307d5c"
   },
   "outputs": [],
   "source": [
    "#max_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a62c5780",
   "metadata": {
    "id": "a62c5780"
   },
   "outputs": [],
   "source": [
    "# define a dict to encode labels\n",
    "\n",
    "# labels = {\n",
    "#           'Expense': 0,\n",
    "#           'Income': 1\n",
    "#          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a03f1d3d",
   "metadata": {
    "id": "a03f1d3d"
   },
   "outputs": [],
   "source": [
    "# #https://pytorch.org/tutorials/beginner/basics/data_tutorial.html\n",
    "\n",
    "# class customDataset(Dataset):\n",
    "\n",
    "#     # initialize the attributes or properties of an object.\n",
    "#     def __init__(self, dataframe, tokenizer, max_len):\n",
    "\n",
    "#         self.data = dataframe\n",
    "#         self.tokenizer = tokenizer\n",
    "#         self.texts = dataframe.texts\n",
    "#         self.labels = [labels[l] for l in df1['label']]\n",
    "#         self.max_len = max_length\n",
    "\n",
    "#     \"\"\"\n",
    "#     necessary for DataLoader class batching, determine the total number of batches in an epoch and for initializing the DataLoader.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.texts)\n",
    "\n",
    "#     \"\"\"\n",
    "#     This method retrieves a single sample from the dataset at the given index idx.\n",
    "#     It enables you to index into the dataset using square brackets ([]).\n",
    "#     In the context of training, this method is used by the DataLoader to retrieve individual samples during iteration.\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "\n",
    "#         texts = str(self.texts[index])\n",
    "#         texts = \" \".join(texts.split())\n",
    "#         #print('get item texts -', texts)\n",
    "\n",
    "#         inputs = self.tokenizer(\n",
    "#                                 texts,\n",
    "#                                 add_special_tokens=True,\n",
    "#                                 padding='max_length',\n",
    "#                                 max_length = max_length,\n",
    "#                                 truncation=True,\n",
    "#                                 return_tensors='pt'\n",
    "#                                )\n",
    "\n",
    "#         ids = inputs['input_ids']\n",
    "#         mask = inputs['attention_mask']\n",
    "\n",
    "#         return {\n",
    "#                 'ids': ids,\n",
    "#                 'mask': mask,\n",
    "#                 'labels': self.labels[index]\n",
    "#         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbec120a",
   "metadata": {
    "id": "fbec120a",
    "outputId": "3c8a86d4-009a-4f24-e4b4-413650529e3c"
   },
   "outputs": [],
   "source": [
    "# train_size = 0.8 # 80% training data\n",
    "\n",
    "# # sample training data\n",
    "# train_df = df1.sample(frac=0.8, random_state=200)\n",
    "# # Test data\n",
    "# test_df = df1.drop(train_df.index).reset_index(drop=True)\n",
    "# # reset index\n",
    "# train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# print(\"Original Dataset {}\".format(df1.shape))\n",
    "# print(\"Training Dataset {}\".format(train_df.shape))\n",
    "# print(\"Test Dataset {}\".format(test_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba99f873",
   "metadata": {
    "id": "ba99f873"
   },
   "outputs": [],
   "source": [
    "# Initialize the class\n",
    "#train_data = customDataset(train_df, tokenizer, max_length)\n",
    "#test_data = customDataset(test_df, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76a33a41",
   "metadata": {
    "id": "76a33a41"
   },
   "outputs": [],
   "source": [
    "# save file\n",
    "#df1.to_csv('df_nlp_fin.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3817e99",
   "metadata": {
    "id": "a3817e99"
   },
   "outputs": [],
   "source": [
    "# # Parallelize batch loading using pytorch DataLoader class\n",
    "\n",
    "# # https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "\n",
    "# TRAIN_BATCH_SIZE = 8\n",
    "# VALID_BATCH_SIZE = 4\n",
    "\n",
    "# train_params = {\n",
    "#                 'batch_size': TRAIN_BATCH_SIZE,\n",
    "#                 'shuffle': True,\n",
    "#                 'num_workers': 0\n",
    "#                 }\n",
    "\n",
    "# test_params = {\n",
    "#                 'batch_size': VALID_BATCH_SIZE,\n",
    "#                 'shuffle': True,\n",
    "#                 'num_workers': 0\n",
    "#                 }\n",
    "\n",
    "# training_loader = DataLoader(train_data, **train_params)\n",
    "# testing_loader = DataLoader(test_data, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef510a4",
   "metadata": {
    "id": "cef510a4"
   },
   "source": [
    "### Creating the Neural Network for fine-tuning\n",
    "\n",
    "**Neural Network**\n",
    "\n",
    "- We will be creating a neural network with the BERTClass.\n",
    "- This network will have the Bert model. Followed by a Dropout and Linear Layer. They are added for the purpose of Regulariaztion and Classification respectively.\n",
    "- In the forward loop, there are 2 output from the BertModel layer.\n",
    "- The second output output_1 or called the pooled output is passed to the Drop Out layer and the subsequent output is given to the Linear layer.\n",
    "- Keep note the number of dimensions for Linear Layer is 2 because that is the total number of categories in which we are looking to classify our model.\n",
    "- The data will be fed to the BertClass as defined in the dataset.\n",
    "- Final layer outputs is what will be used to calcuate the loss and to determine the accuracy of models prediction.\n",
    "- We will initiate an instance of the network called model. This instance will be used for training and then to save the final trained model for future inference.\n",
    "\n",
    "> More on **dropout layer**:\n",
    "\n",
    "- Dropout is a regularization technique designed to prevent overfitting in neural networks during training. Overfitting occurs when a model learns to perform well on the training data but fails to generalize to new, unseen data.\n",
    "\n",
    "- During each forward pass in training, individual neurons (or units) in the dropout layer are \"dropped out\" with a certain probability. This means their output is set to zero. The output of DistilBERT (output_1) in this model.\n",
    "\n",
    "- nn.Dropout(0.3) refers to the probability of an input unit being zeroed out during each training step.\n",
    "\n",
    "> More on **linear layer**:\n",
    "\n",
    "- The linear layer (also known as the dense layer or fully connected layer) is responsible for transforming input features into output features through linear transformation.\n",
    "\n",
    "\n",
    "- Each neuron in the linear layer is connected to every neuron in the previous layer, forming a fully connected structure. The output of each neuron is the weighted sum of its inputs plus a bias term.\n",
    "\n",
    "\n",
    "- The linear transformation is defined by a weight matrix and a bias vector. If the input has size input_size and the output has size output_size, the weight matrix is of shape (output_size, input_size).\n",
    "\n",
    "- Activation Function: After the linear transformation, an activation function (e.g., ReLU, sigmoid, softmax) is often applied element-wise to introduce non-linearity to the model. The activation function allows the network to capture more complex relationships in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9278ae3c",
   "metadata": {
    "id": "9278ae3c",
    "outputId": "1734f13d-6e87-4021-b29a-54067ad9c24e"
   },
   "outputs": [],
   "source": [
    "# # Creating the customized model, by adding a drop out and a dense layer on top of distil bert to get the final output for the model.\n",
    "# from torch import nn\n",
    "\n",
    "# # Docs: https://pytorch.org/docs/stable/nn.html\n",
    "# class BERTClass(torch.nn.Module): # Inherits from nn.Module, the base class for all PyTorch neural network modules.\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super(BERTClass, self).__init__() # call constructor `__init__` method of the superclass nn.module before initializing the subclass BERTClass\n",
    "#         self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "#         self.dropout = nn.Dropout(0.3) # Applies dropout regularization to the output of BERT\n",
    "#         self.linear = nn.Linear(768, 1) # Linear layer for classification with input size 768 (BERT hidden size) and output size 2 (number of classes).\n",
    "#         self.sigmoid = nn.Sigmoid() # Sigmoid activation function, an S-shaped function to map an input value to probabilities between 0 and 1.\n",
    "\n",
    "#     def forward(self, ids, mask):\n",
    "\n",
    "#         #outputs = self.bert(ids, attention_mask = mask, return_dict=True) # Forward pass through the BERT model, taking input IDs (input_id) and attention mask (mask). It returns both the last layer hidden states (denoted by _) and the pooled output (representing the entire input sequence).\n",
    "\n",
    "#         _, pooler_output = self.bert(ids, attention_mask = mask, return_dict=False) # Forward pass through the BERT model, taking input IDs (input_id) and attention mask (mask). It returns both the last layer hidden states (denoted by _) and the pooled output (representing the entire input sequence).\n",
    "\n",
    "#         dropout_output = self.dropout(pooler_output) # Applies dropout to the pooled output.\n",
    "#         linear_output = self.linear(dropout_output) # Passes the dropout output through a linear layer for classification.\n",
    "#         final_layer = self.sigmoid(linear_output) # Applies the Sigmoid activation function to the linear output.\n",
    "\n",
    "#         return final_layer\n",
    "\n",
    "# bmodel = BERTClass()\n",
    "# bmodel.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702422c5",
   "metadata": {
    "id": "702422c5"
   },
   "source": [
    "### Loss Function and Optimizer\n",
    "\n",
    "- The Loss is defined in the next cell as loss_fn.\n",
    "- As defined above, the loss function used will be a combination of Binary Cross Entropy which is implemented as BCELogits Loss in PyTorch\n",
    "- Optimizer is defined in the next cell.\n",
    "- Optimizer is used to update the weights of the neural network to improve its performance.\n",
    "\n",
    "#### Further Reading\n",
    "\n",
    "- You can refer to my [Pytorch Tutorials](https://github.com/abhimishra91/pytorch-tutorials) to get an intuition of Loss Function and Optimizer.\n",
    "- [Pytorch Documentation for Loss Function](https://pytorch.org/docs/stable/nn.html#loss-functions)\n",
    "- [Pytorch Documentation for Optimizer](https://pytorch.org/docs/stable/optim.html)\n",
    "- Refer to the links provided on the top of the notebook to read more about `BertModel`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "231cb855",
   "metadata": {
    "id": "231cb855"
   },
   "outputs": [],
   "source": [
    "#LEARNING_RATE = 1e-05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6d82b9c5",
   "metadata": {
    "id": "6d82b9c5"
   },
   "outputs": [],
   "source": [
    "# def loss_fn(outputs, targets):\n",
    "\n",
    "#     return torch.nn.BCELoss()(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e67c717c",
   "metadata": {
    "id": "e67c717c"
   },
   "outputs": [],
   "source": [
    "#optimizer = torch.optim.Adam(params =  bmodel.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2a140",
   "metadata": {
    "id": "6ad2a140"
   },
   "source": [
    "### Fine Tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09ef4b4",
   "metadata": {},
   "source": [
    "Here's a detailed breakdown of what each part does:\n",
    "\n",
    "Purpose:\n",
    "\n",
    "This function trains the model (bmodel) on a given epoch (epoch) of the training data. `train(epoch)` defines the training loop for a neural network model using PyTorch. \n",
    "\n",
    "Steps:\n",
    "\n",
    "1. Set Model to Train Mode:\n",
    "\n",
    "`bmodel.train()`: This line sets the model to training mode. This might activate dropout layers or other functionalities specific to the training process.\n",
    "\n",
    "2. Iterate Through Training Data:\n",
    "\n",
    "`for _, data in enumerate(training_loader, 0)`: This line iterates through the training data loader (training_loader).\n",
    "\n",
    "_: This underscore variable is a placeholder and is typically not used within the loop.\n",
    "\n",
    "data: This variable represents a batch of training data retrieved from the data loader. It's usually a dictionary containing various elements like input IDs, attention mask, and labels.\n",
    "\n",
    "3. Process Labels:\n",
    "\n",
    "`labels = data['labels'].to(device, dtype = torch.float).unsqueeze(1)`: This line processes the labels (data['labels']) from the data batch.\n",
    "\n",
    "Converts them to the device and float data type `(torch.float)` assuming labels are continuous values (e.g., sentiment scores).\n",
    "\n",
    "Uses unsqueeze(1) to insert a new dimension at index 1. This might be necessary depending on the expected input format for the loss function.\n",
    "\n",
    "Reshape Input Data (if necessary):\n",
    "\n",
    "`ids = ids.view(-1, ids.size(-1))`: This line reshapes the input IDs (ids) if needed. The view function allows reshaping the tensor. Here, -1 in the first dimension infers the size based on the other dimensions, and `ids.size(-1)` keeps the last dimension intact (usually the sequence length).\n",
    "\n",
    "`mask = mask.view(-1, mask.size(-1))`: This line performs similar reshaping for the attention mask (mask) if necessary.\n",
    "\n",
    "Model Forward Pass:\n",
    "\n",
    "`outputs = bmodel(ids, mask)`: This line performs the forward pass of the model (bmodel). It feeds the input IDs (ids) and attention mask (mask) into the model and retrieves the model's output (outputs). These outputs might be logits (unnormalized probabilities) or other task-specific predictions.\n",
    "\n",
    "4. Calculate Loss:\n",
    "\n",
    "`loss = loss_fn(outputs, labels)`: This line calculates the loss between the model's output (outputs) and the ground-truth labels (labels). The specific loss function (loss_fn) depends on the task (e.g., cross-entropy loss for classification).\n",
    "\n",
    "\n",
    "5. if _%100==0:: This conditional block executes every 100th iteration.\n",
    "\n",
    "`print('itr',_)`: Prints the current iteration number (again, not very informative).\n",
    "print(f'Epoch: {epoch}, Loss: {loss.item()}'): Prints the current epoch number (epoch) and the calculated loss value (loss.item()) as a floating-point number.\n",
    "\n",
    "6. Backpropagation and Optimization:\n",
    "\n",
    "`optimizer.zero_grad()`: This line zeros out the gradients from the previous iteration before accumulating new gradients for the current batch.\n",
    "\n",
    "`loss.backward()`: This line performs backpropagation. It calculates the gradients of the loss function with respect to the model's parameters.\n",
    "\n",
    "`optimizer.step()`: This line updates the model's parameters using the optimizer. \n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "The three lines at the bottom of the `training` function represent the core training loop steps within a neural network using PyTorch:\n",
    "\n",
    "`optimizer.zero_grad() (Clears Gradients):`\n",
    "\n",
    "This line is crucial for efficient training. In neural networks, the gradients represent how much each parameter (weight and bias) in the model contributed to the overall error (loss) during the previous training iteration.\n",
    "Calling `optimizer.zero_grad()` explicitly sets all the gradients to zero before starting a new iteration. \n",
    "This ensures that gradients from the current iteration are accumulated accurately without being influenced by the previous ones.\n",
    "\n",
    "`loss.backward() (Backpropagation):`\n",
    "\n",
    "This line performs backpropagation, a vital algorithm for training neural networks. Backpropagation efficiently calculates the gradients of the loss function with respect to each parameter in the model.\n",
    "\n",
    "It works by:\n",
    "    \n",
    "1. Starting from the output layer and propagating the error backward through the network layer by layer.\n",
    "\n",
    "2. Utilizing the chain rule of differentiation to calculate the gradients for each layer's weights and biases.\n",
    "                                                                        \n",
    "3. The calculated gradients provide essential information on how to adjust the model's parameters in the right direction to minimize the loss on future data.\n",
    "\n",
    "`optimizer.step()` \n",
    "                                                                         \n",
    "(Parameter Update):\n",
    "\n",
    "This line performs the parameter update step using the chosen optimizer (optimizer).\n",
    "                                                                         \n",
    "The optimizer utilizes the gradients calculated by backpropagation (loss.backward()) to update the weights and biases of the model.\n",
    "                                                                         \n",
    "The goal of this update is to minimize the loss function and improve the models performance on future data.\n",
    "\n",
    "Different optimizers use various algorithms to update the parameters, with some popular choices including:\n",
    "\n",
    "Stochastic Gradient Descent (SGD): A fundamental optimizer that updates weights in the direction opposite their gradients, with a learning rate controlling the step size.\n",
    "\n",
    "Momentum: An extension of SGD that considers past gradients, accelerating convergence.\n",
    "\n",
    "Adam (Adaptive Moment Estimation): A popular optimizer that dynamically adjusts the learning rate for each parameter based on historical gradients.\n",
    "\n",
    "\n",
    "In Summary:\n",
    "\n",
    "These three steps work in a loop during training:\n",
    "\n",
    "A batch of data is fed through the network (forward pass).\n",
    "                                                                                                 \n",
    "The loss is calculated based on the model's output and the ground-truth labels.\n",
    "                                                                                                 \n",
    "`optimizer.zero_grad()` clears gradients from the previous iteration.\n",
    "                                                                                                 \n",
    "`loss.backward()` performs backpropagation to calculate gradients for each parameter.\n",
    "                                                                                                 \n",
    "`optimizer.step()` uses the gradients to update the model's weights and biases.\n",
    "                                                                                                 \n",
    "Steps 1-5 are repeated for multiple epochs (iterations over the entire training data) to gradually refine the model's performance.\n",
    "\n",
    "In essence,\n",
    "\n",
    "Backpropagation calculates how each parameter affects the loss.\n",
    "             \n",
    "The optimizer uses this information to adjust the parameters and steer the model towards better predictions.\n",
    "             \n",
    "Clearing gradients (optimizer.zero_grad()) ensures clean accumulation of gradients in each iteration for efficient training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9b3d170",
   "metadata": {
    "id": "e9b3d170"
   },
   "outputs": [],
   "source": [
    "# def train(epoch):\n",
    "\n",
    "#     # set the model in train() mode\n",
    "#     bmodel.train()\n",
    "\n",
    "#     for _,data in enumerate(training_loader, 0):\n",
    "\n",
    "#         print('iteration {}'.format(_))\n",
    "#         print('Train Batch size', len(data['ids']))\n",
    "\n",
    "#         ids = data['ids'].to(device, dtype = torch.long)\n",
    "#         mask = data['mask'].to(device, dtype = torch.long)\n",
    "\n",
    "#         # original representation of labels / targets\n",
    "#         labels = data['labels'].to(device, dtype = torch.float).unsqueeze(1) # insert new dimension at 1 index\n",
    "\n",
    "#         # Reshape ids and mask to be 2D\n",
    "#         ids = ids.view(-1, ids.size(-1))\n",
    "#         mask = mask.view(-1, mask.size(-1))\n",
    "\n",
    "#         outputs = bmodel(ids, mask)\n",
    "\n",
    "#         loss = loss_fn(outputs, labels)\n",
    "\n",
    "#         if _%100==0:\n",
    "#             print('itr',_)\n",
    "#             print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7707d57d",
   "metadata": {
    "id": "7707d57d",
    "outputId": "8cc2e2e6-cd04-4333-f015-314b0acc0839"
   },
   "outputs": [],
   "source": [
    "# # Start the Training run\n",
    "# EPOCHS = 10\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "#     print('epochs', epoch)\n",
    "#     train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433f52b",
   "metadata": {
    "id": "1433f52b"
   },
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a87771c3",
   "metadata": {
    "id": "a87771c3"
   },
   "outputs": [],
   "source": [
    "# def validation(epoch):\n",
    "\n",
    "#     # set the model in eval() mode\n",
    "#     bmodel.eval()\n",
    "\n",
    "#     fin_targets=[]\n",
    "#     fin_outputs=[]\n",
    "\n",
    "#     with torch.no_grad():\n",
    "\n",
    "#         for _, data in enumerate(testing_loader, 0):\n",
    "\n",
    "#             #print('iteration {}'.format(_))\n",
    "#             #print('Train Batch size', len(data['ids']))\n",
    "\n",
    "#             ids = data['ids'].to(device, dtype = torch.long)\n",
    "#             mask = data['mask'].to(device, dtype = torch.long)\n",
    "#             #token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n",
    "\n",
    "#             # original representation of labels / targets\n",
    "#             targets = data['labels'].to(device, dtype = torch.float)\n",
    "\n",
    "#             # Reshape ids and mask to be 2D\n",
    "#             ids = ids.view(-1, ids.size(-1))\n",
    "#             mask = mask.view(-1, mask.size(-1))\n",
    "\n",
    "#             outputs = bmodel(ids, mask)\n",
    "\n",
    "#             fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "#             fin_outputs.extend(outputs.cpu().detach().numpy().tolist())\n",
    "\n",
    "#         #print(\"fin targets\", fin_targets)\n",
    "#         #print(\"fin outputs\", fin_outputs)\n",
    "\n",
    "#     return fin_outputs, fin_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2097689f",
   "metadata": {
    "id": "2097689f",
    "outputId": "e670eba2-d8ad-45a9-f8b8-209bcb09c2b6"
   },
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCHS):\n",
    "\n",
    "#     print('epoch', epoch)\n",
    "\n",
    "#     outputs, targets = validation(epoch)\n",
    "\n",
    "#     #print(\"outputs\", outputs[:5])\n",
    "#     #print(\"targets\", targets[:5])\n",
    "\n",
    "#     outputs = np.array(outputs) >= 0.5\n",
    "#     accuracy = metrics.accuracy_score(targets, outputs)\n",
    "#     f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
    "#     f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
    "\n",
    "#     print(f\"Accuracy Score = {accuracy}\")\n",
    "#     print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
    "#     print(f\"F1 Score (Macro) = {f1_score_macro}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d9816",
   "metadata": {},
   "source": [
    "The classification accuracy is **~71%** based on fine-tuning BERT model. This is an appropriate baseline for our experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13041ac",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba949902",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4daeaa4e",
   "metadata": {},
   "source": [
    "## Let's cover some building block concepts\n",
    "\n",
    "For practical tips on Finetuning LLMs refer to: https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47dc30",
   "metadata": {},
   "source": [
    "### Quantization\n",
    "\n",
    "Quantization is the process of converting the pre-trained LLM to a lower precision (e.g., from 32-bit floating point to 8-bit integers).\n",
    "\n",
    "This involves converting both weights and activations, or just weights depending on the desired balance between performance and resource savings.\n",
    "\n",
    "Moreover, one can not only freeze the existing base model but also quantize it (which means, shrinking down its size). A neural network's parameters are typically saved in either float32 (which means, 32 bits or 4 bytes are used to store each parameter value) or float16 (which means, 16 bits or half a byte - also called half precision). However, with some clever algorithms one can shrink each parameter to just 8 or 4 bits (half a byte!), without significant effect on final performance. Read all about it here: https://huggingface.co/blog/4bit-transformers-bitsandbytes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18e1c7b",
   "metadata": {},
   "source": [
    "### LoRA\n",
    "\n",
    "PEFT, Parameter Efficient Fine-Tuning, is a collection of techniques (p-tuning, prefix-tuning, IA3, Adapters, and LoRa) designed to fine-tune large models using a much smaller set of training parameters while preserving the performance levels typically achieved through full fine-tuning.\n",
    "\n",
    "LoRA, Low-Rank Adaptation, is a PEFT method that shares similarities with Adapter layers. Its primary objective is to reduce the model's trainable parameters. LoRA's operation involves `learning a low rank update matrix while keeping the pre-trained weights frozen.`\n",
    "\n",
    "<img src=\"https://github.com/kevalshah90/token-classification-fine-tuning/blob/main/lora.png?raw=1\" width=\"700px\" height=\"700px\">\n",
    "\n",
    "\n",
    "As illustrated above, the decomposition of Î”W means that we represent the large matrix Î”W with two smaller LoRA matrices, A and B. If A has the same number of rows as Î”W and B has the same number of columns as Î”W, we can write the decomposition as Î”W = AB. (AB is the matrix multiplication result between matrices A and B.) \n",
    "\n",
    "How much memory does this save? It depends on the rank r, which is a hyperparameter. For example, if Î”W has 10,000 rows and 20,000 columns, it stores 200,000,000 parameters. If we choose A and B with r=8, then A has 10,000 rows and 8 columns, and B has 8 rows and 20,000 columns, that's 10,000Ã—8 + 8Ã—20,000 = 240,000 parameters, which is about 830Ã— less than 200,000,000.\n",
    "\n",
    "Of course, A and B can't capture all the information that Î”W could capture, but this is by design. When using LoRA, we hypothesize that the model requires W to be a large matrix with full rank to capture all the knowledge in the pretraining dataset. However, when we finetune an LLM, we don't need to update all the weights and capture the core information for the adaptation in a smaller number of weights than Î”W would; hence, we have the low-rank updates via AB.\n",
    "\n",
    "\n",
    "**LoRA's Matrix Decomposition Steps:**\n",
    "\n",
    "Approximate Weight Change: The core idea is that the change in weights due to fine-tuning (Î”W) can be approximated by a product of two lower-rank matrices, A and B:\n",
    "\n",
    "Î”W â‰ˆ A * B\n",
    "\n",
    "Î”W: Represents the difference between the pre-trained weights and the weights after fine-tuning for the new task.\n",
    "\n",
    "A: A low-rank matrix with dimensions typically much smaller than W (e.g., A might be d x r, where d is the number of features in the original weight matrix and r is a significantly smaller value representing the rank).\n",
    "\n",
    "B: Another low-rank matrix with dimensions typically B = r x d (same number of rows as A's columns and same number of columns as W's rows).\n",
    "\n",
    "Training the Low-Rank Matrices: During fine-tuning, instead of directly modifying the entire weight matrix (W), LoRA focuses on training these smaller matrices, A and B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f44c4",
   "metadata": {},
   "source": [
    "**Quantized LoRa or QLoRa**\n",
    "\n",
    "QLoRA, short for quantized LoRA, is a technique that further reduces memory usage during finetuning. During backpropagation, QLoRA quantizes the pretrained weights to 4-bit precision and uses paged optimizers to handle memory spikes.\n",
    "\n",
    "One can save GPU memory when using QLoRA. However, this comes at a increased training runtime caused by the additional quantization and dequantization of the pretrained model weights in QLoRA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d94b25",
   "metadata": {},
   "source": [
    "### Attention\n",
    "\n",
    "Self-attention mechanism is used to capture the dependencies between different words in a sequence. However, as the length of the sequence increases, the computational cost of computing self-attention grows quadratically, making it inefficient for long sequences.\n",
    "\n",
    "Let's break this down with an example:\n",
    "\n",
    "Suppose we have a sentence with `n` words, and we represent each word with a vector of dimension `d`. In the self-attention mechanism, we compute attention scores between each pair of words. \n",
    "\n",
    "This involves three main steps:\n",
    "\n",
    "1. Computing the `Query`, `Key`, and `Value` vectors: For `each word` in the `sequence`, we linearly transform the word embeddings to obtain `Query`, `Key`, and `Value` vectors of dimension `d`.\n",
    "   \n",
    "2. Computing Attention Scores: For each word in the sequence, we compute attention scores with respect to all other words. This involves calculating the dot product between the Query vector of the current word and the Key vectors of all other words, followed by applying a softmax function to obtain attention weights.\n",
    "\n",
    "3. Computing the Weighted Sum: We use the attention weights to compute a weighted sum of the Value vectors of all words, producing the output for the current word.\n",
    "   \n",
    "Now, let's analyze the computational complexity of each step:\n",
    "\n",
    "Computing `Query`, `Key`, and `Value` vectors: This step involves a simple linear transformation for each word, resulting in a complexity of `O(nd^2)`, where `n` is the number of words and `d` is the dimension of the word embeddings.\n",
    "\n",
    "Computing Attention Scores: For each word, we compute attention scores with respect to all other words. Since there are `n` words and for each word, we perform a dot product with `n` key vectors, the complexity of this step is `O(n^2d)`.\n",
    "\n",
    "Computing the Weighted Sum: This step involves a weighted sum operation for each word, which has a complexity of `O(nd)`.\n",
    "\n",
    "When we sum up the complexities of all three steps, the dominant term is the second step, which grows quadratically with the length of the sequence `(n)`. Therefore, the overall complexity of the self-attention mechanism in the vanilla transformer architecture is `O(n^2d)` or squared compute cost. This quadratic growth becomes a bottleneck for long sequences, making it less scalable compared to architectures with linear or sub-linear complexities.\n",
    "\n",
    "The critical point is that the number of computations grows with the product `(Np * Nci)` of the sequence length `(Np)` in the previous layer. Here, `Nci` represent the current token in the sequence and we compute attention scores for each token in the current sequence. In mathematical terms, this product represents the square of the sequence length `(N^2)`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53af9f54",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42244ef",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65b42f4",
   "metadata": {},
   "source": [
    "### Fine-Tuning Mistral-7b\n",
    "\n",
    "<img src=\"https://github.com/kevalshah90/token-classification-fine-tuning/blob/main/ft.png?raw=1\" width=\"500px\" height=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9006f97",
   "metadata": {},
   "source": [
    "Mistral 7B v0.1, with 7.3 billion parameters, is the first LLM introduced by Mistral AI. The main novel techniques used in Mistral 7B's architecture are:\n",
    "\n",
    "- Sliding Window Attention: Replace the full attention (square compute cost) with a sliding window based attention where each token can attend to at most 4,096 tokens from the previous layer (linear compute cost). This mechanism enables Mistral 7B to handle longer sequences, where higher layers can access historical information beyond the window size of 4,096 tokens.\n",
    "\n",
    "- Grouped-query Attention: used in Llama 2 as well, the technique optimizes the inference process (reduce processing time) by caching the key and value vectors for previously decoded tokens in the sequence.\n",
    "\n",
    "\n",
    "https://magazine.sebastianraschka.com/p/finetuning-large-language-models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b119dd4",
   "metadata": {},
   "source": [
    "#### 1. Split the dataset in Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "332e5de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Device: cuda'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    \n",
    "f\"Device: {device}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5adfd06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>Less: Other Other - Check Processing Fees</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1380</th>\n",
       "      <td>Header BAD DEBT</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>Plus: Misc. Other Income Additional Other Income</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1410</th>\n",
       "      <td>Plus: Misc. Other Income Deposit Fee</td>\n",
       "      <td>Income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>Less: Office Expenses Employee Relations</td>\n",
       "      <td>Expense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 texts    label\n",
       "1485         Less: Other Other - Check Processing Fees  Expense\n",
       "1380                                   Header BAD DEBT   Income\n",
       "1921  Plus: Misc. Other Income Additional Other Income   Income\n",
       "1410              Plus: Misc. Other Income Deposit Fee   Income\n",
       "2037          Less: Office Expenses Employee Relations  Expense"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's print out data first\n",
    "df2.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "407454e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a dict to encode labels\n",
    "labels = {\n",
    "          'Expense': 0,\n",
    "          'Income': 1\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a3b35008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    3000\n",
       "0    3000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's update the labels with 0 or 1\n",
    "df2[\"label\"] = df2[\"label\"].map(labels)\n",
    "df2[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1ccb6cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Less: Gas Gas - Vacancy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total TOTAL INCOME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Less: Marketing Permanent Signage</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gross Potential Rent Potential Rent</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Less: Unit Turnover RR - Appliance - Dishwasher</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             texts  label\n",
       "0                          Less: Gas Gas - Vacancy      0\n",
       "1                               Total TOTAL INCOME      1\n",
       "2                Less: Marketing Permanent Signage      0\n",
       "3              Gross Potential Rent Potential Rent      1\n",
       "4  Less: Unit Turnover RR - Appliance - Dishwasher      0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "df2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3619a7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df2.sample(frac=0.75, random_state=200)\n",
    "rem_df = df2.drop(train_df.index)\n",
    "\n",
    "# validation set\n",
    "val_df = rem_df.sample(frac=0.5, random_state=200)\n",
    "test_df = rem_df.drop(val_df.index)\n",
    "\n",
    "train_df.to_csv(\"train.csv\", index=None)\n",
    "val_df.to_csv(\"validation.csv\", index=None)\n",
    "test_df.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492b2e14",
   "metadata": {},
   "source": [
    "#### 2. Create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9786d424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "470f1ecbb4a34ae7bfcbcc466321fd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5c21b2f3964a31977e14c68bb9a68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a8378b9cdc648f7b17a2f894fa63414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc23b1835c03466dbab9f2f157665a79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10b6a97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1304c46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class customDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        \n",
    "        # as string\n",
    "        self.data['texts'] = self.data['texts'].astype(str)\n",
    "        \n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data['texts']]\n",
    "        \n",
    "        # If max_length is not specified, use the longest text length\n",
    "        if max_length is None:\n",
    "            self.max_length = max(len(text) for text in self.encoded_texts)\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "        \n",
    "        # Pad sequences to the longest sequence\n",
    "        self.encoded_texts = [\n",
    "            encoded_text + [tokenizer.eos_token_id] * (self.max_length - len(encoded_text))\n",
    "            for encoded_text in self.encoded_texts\n",
    "        ]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        encoded = self.encoded_texts[index]\n",
    "        label = self.data.iloc[index][\"label\"]\n",
    "        return (\n",
    "            torch.tensor(encoded, dtype=torch.long),\n",
    "            torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "55a8a861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "train_dataset = customDataset(\n",
    "                                csv_file=\"train.csv\",\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=None\n",
    "                             )\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "171891fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "val_dataset = customDataset(\n",
    "                                csv_file=\"validation.csv\",\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=None\n",
    "                             )\n",
    "\n",
    "print(val_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5bbd23c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "test_dataset = customDataset(\n",
    "                                csv_file=\"test.csv\",\n",
    "                                tokenizer=tokenizer,\n",
    "                                max_length=None\n",
    "                             )\n",
    "\n",
    "print(test_dataset.max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688aaa27",
   "metadata": {},
   "source": [
    "Next, we use the dataset to instantiate the data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "71d7aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 2\n",
    "batch_size = 25\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "                            dataset=train_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=num_workers,\n",
    "                            drop_last=True,\n",
    "                         )\n",
    "\n",
    "\n",
    "val_loader = DataLoader(\n",
    "                            dataset=val_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            num_workers=num_workers,\n",
    "                            drop_last=False,\n",
    "                        )\n",
    "\n",
    "\n",
    "test_loader = DataLoader(\n",
    "                            dataset=test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            num_workers=num_workers,\n",
    "                            drop_last=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8748b8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([25, 25])\n",
      "Label batch dimensions torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for input_batch, target_batch in train_loader:\n",
    "    pass\n",
    "\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "4bac3534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 training batches\n",
      "30 validation batches\n",
      "30 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d79583",
   "metadata": {},
   "source": [
    "#### 3. Initializing an LLM with pre-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f29b797",
   "metadata": {},
   "source": [
    "Let's load a pre-trained LLM with 4-bit quantization precision for its weights.\n",
    "\n",
    "- `load_in_4bit=True`: This flag indicates that the model's weights should be loaded using 4-bit precision. Using 4-bit precision reduces the model's memory footprint significantly compared to standard 32-bit or 16-bit precision.\n",
    "\n",
    "\n",
    "- `bnb_4bit_quant_type=\"nf4\"`: Specifies the type of 4-bit quantization to use. \"nf4\" stands for Normal Float 4-bit. This quantization method aims to maintain a normal distribution of floating-point values, which helps preserve the model's performance despite the lower precision.\n",
    "\n",
    "\n",
    "- `bnb_4bit_compute_dtype=torch.bfloat16`: Sets the computation data type to bfloat16 (Brain Floating Point 16). While the model's weights are stored in 4-bit precision, the computations during inference or training will be carried out in bfloat16. This format is a 16-bit floating-point type that balances computational efficiency and numerical stability, providing a good trade-off between precision and performance.\n",
    "\n",
    "\n",
    "- `bnb_4bit_quant_storage=torch.bfloat16`: Specifies that the storage format for the quantized weights should be bfloat16. This helps in maintaining a balance between reduced memory usage and preserving enough information to ensure model accuracy.\n",
    "\n",
    "\n",
    "**Key difference between `load_in_4bit` and `bnb_4bit_compute_dtype`:**\n",
    "\n",
    "Weight Storage: `load_in_4bit=True` ensures that the model's weights are stored in 4-bit precision, reducing memory usage.\n",
    "\n",
    "Computation Precision: `bnb_4bit_compute_dtype=torch.bfloat16` sets the precision for the computations. While weights are in 4-bit, the activations and intermediate results during forward and backward passes will use torch.bfloat16, combining the benefits of quantization with the advantages of higher precision computations.\n",
    "\n",
    "- `Mistral-7b`@`32-bit (4-bytes)` precision would be 28gb memory. (7bx4) | 1 byte = 8 bit\n",
    "\n",
    "- Quantized `Mistral-7b` @ `4-bit (0.5 bytes)` precision would be 3.5gb memory. (7bx0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "202d6dba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BitsAndBytesConfig {\n",
       "  \"_load_in_4bit\": true,\n",
       "  \"_load_in_8bit\": false,\n",
       "  \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
       "  \"bnb_4bit_quant_storage\": \"bfloat16\",\n",
       "  \"bnb_4bit_quant_type\": \"nf4\",\n",
       "  \"bnb_4bit_use_double_quant\": true,\n",
       "  \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "  \"llm_int8_has_fp16_weight\": false,\n",
       "  \"llm_int8_skip_modules\": null,\n",
       "  \"llm_int8_threshold\": 6.0,\n",
       "  \"load_in_4bit\": true,\n",
       "  \"load_in_8bit\": false,\n",
       "  \"quant_method\": \"bitsandbytes\"\n",
       "}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "                                    load_in_4bit=True, # This flag indicates that the model should be loaded with 4-bit precision for its weights.\n",
    "                                    bnb_4bit_quant_type=\"nf4\", # Specifies the type of 4-bit quantization to use. \"nf4\" stands for Normal Float 4-bit, which is a quantization method that attempts to maintain a normal distribution of floating-point values to preserve model performance despite the reduced precision.\n",
    "                                    bnb_4bit_compute_dtype=torch.bfloat16, # Sets the computation data type to bfloat16 (Brain Floating Point), a 16-bit floating-point format. While the weights are stored in 4-bit precision, computations during inference or training will be carried out in bfloat16 to balance efficiency and numerical stability.\n",
    "                                    bnb_4bit_use_double_quant=True, # Enables double quantization, a technique that involves an additional quantization step to further reduce the model's size and possibly improve the quantization's impact on model performance.\n",
    "                                    bnb_4bit_quant_storage=torch.bfloat16 # Specifies the storage format for the quantized weights as bfloat16. This helps in maintaining a balance between reduced memory usage and preserving sufficient information for model accuracy.\n",
    "                               )\n",
    "\n",
    "bnb_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "56b6a8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device (replace 'cuda:0' with the appropriate GPU if you have multiple GPUs)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Set the device for PyTorch\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a0e6c0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "81fd6596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6089384448\n",
      "4973572608\n"
     ]
    }
   ],
   "source": [
    "# Before clearing GPU memory\n",
    "print(torch.cuda.memory_allocated())\n",
    "\n",
    "# Clear GPU memory\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "# After clearing GPU memory\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d994a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.memory_allocated() == 0:\n",
    "    model_4bit = AutoModelForCausalLM.from_pretrained(\n",
    "                                                        \"mistralai/Mistral-7B-v0.1\",\n",
    "                                                        quantization_config=bnb_config,\n",
    "                                                        device_map=\"cuda:0\"\n",
    "                                                     )\n",
    "\n",
    "    model_4bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c7a186af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': device(type='cuda', index=0)}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4bit.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b34f7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to disk\n",
    "#model.save_pretrained(os.getcwd() + \"/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "32414b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from disk\n",
    "#model = AutoModelForCausalLM.from_pretrained(os.getcwd() + \"/model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e99df6",
   "metadata": {},
   "source": [
    "We run into `OOM` error, when attempting to load `mistral-7b` via HF Transformers. As the Mistral model has 7 billion parameters, that would require about 14GB of GPU RAM in half precision (float16), since each parameter is stored in 2 bytes. However, one can shrink down the size of the model using quantization. If the model is quantized to 4 bits (or half a byte per parameter),that requires only about 3.5GB of RAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0ed02846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model configuration: MistralConfig {\n",
      "  \"_name_or_path\": \"mistralai/Mistral-7B-v0.1\",\n",
      "  \"architectures\": [\n",
      "    \"MistralForCausalLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 32768,\n",
      "  \"model_type\": \"mistral\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"quantization_config\": {\n",
      "    \"_load_in_4bit\": true,\n",
      "    \"_load_in_8bit\": false,\n",
      "    \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_storage\": \"bfloat16\",\n",
      "    \"bnb_4bit_quant_type\": \"nf4\",\n",
      "    \"bnb_4bit_use_double_quant\": true,\n",
      "    \"llm_int8_enable_fp32_cpu_offload\": false,\n",
      "    \"llm_int8_has_fp16_weight\": false,\n",
      "    \"llm_int8_skip_modules\": null,\n",
      "    \"llm_int8_threshold\": 6.0,\n",
      "    \"load_in_4bit\": true,\n",
      "    \"load_in_8bit\": false,\n",
      "    \"quant_method\": \"bitsandbytes\"\n",
      "  },\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_theta\": 10000.0,\n",
      "  \"sliding_window\": 4096,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.41.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print model configuration attributes\n",
    "print(f\"Model configuration: {model_4bit.config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9bce56b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18874368 || all params: 1895047168 || trainable%: 0.99598407462964\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "print_trainable_parameters(model_4bit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5962d73b",
   "metadata": {},
   "source": [
    "Let's test / prompt the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9347951f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   1, 2378,  368,  506,  727]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "inputs = tokenizer(\"Do you have time\", return_tensors=\"pt\").to(0)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb0428d",
   "metadata": {},
   "source": [
    "Output is a vector of logits (one for each input token), we convert to a probability distn with a softmax, and can then convert this to a token (eg taking the largest logit, or sampling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "0175a967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " torch.Size([1, 5, 1])\n",
      "Outputs Logits:\n",
      " tensor([[[0.4914],\n",
      "         [0.3885],\n",
      "         [0.3254],\n",
      "         [0.2467],\n",
      "         [0.2212]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # No gradient calculation during inference\n",
    "    outputs = model_4bit(**inputs)\n",
    "    \n",
    "\"\"\"\n",
    "Output is weighted inputs of the output layer.\n",
    "\"\"\"\n",
    "\n",
    "print(\"Outputs:\\n\", outputs.logits.shape)\n",
    "print(\"Outputs Logits:\\n\", outputs.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b902ce4b",
   "metadata": {},
   "source": [
    "Convert the logits to a distribution with a softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "27a157b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6204],\n",
       "         [0.5959],\n",
       "         [0.5806],\n",
       "         [0.5614],\n",
       "         [0.5551]]], device='cuda:0')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "For multi-class problem, we use softmax. \n",
    "\n",
    "For binary classification problem, we use sigmoid activation. \n",
    "\"\"\"\n",
    "#log_probs = outputs.logits.log_softmax(dim=-1)\n",
    "#print(log_probs.shape) # shape = batch x position x d_vocab\n",
    "\n",
    "probs = torch.sigmoid(outputs.logits)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "16e440ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token = probs[0, -1].argmax(dim=-1)\n",
    "# reshape\n",
    "next_token = next_token.view(1,1)\n",
    "next_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587f44d",
   "metadata": {},
   "source": [
    "Append next_token to input tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cab1920d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1, 2378,  368,  506,  727,    0]], device='cuda:0')"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appended = torch.cat((inputs['input_ids'], next_token), dim=-1)\n",
    "appended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "75521ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Do you have time<unk>'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(appended.squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a802775f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95353f0",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959b2afc",
   "metadata": {},
   "source": [
    "For binary classification problem, \n",
    "\n",
    "- The goal is to replace and finetune the output layer `lm_head`\n",
    "- To achieve this, we first freeze the model, meaning that we make all layers non-trainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5be4e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_4bit.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e697fd5",
   "metadata": {},
   "source": [
    "- Then, we replace the output layer `(model.lm_head)`, which originally maps the layer inputs to 32,000 dimensions (the size of the vocabulary)\n",
    "\n",
    "- Since we finetune the model for binary classification (predicting 2 classes, \"Income\" and \"Expense\"), we can replace the output layer as shown below, which will be trainable by default. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "445fabab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=1, bias=False)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4bit.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "86a2a1da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4096"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4bit.get_input_embeddings().embedding_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07955366",
   "metadata": {},
   "source": [
    "`BCELoss` function expects inputs to be probabilities (values between 0 and 1). The loss function measures the discrepancy between predicted probs and true binary labels. By apply `sigmoid` function to the logits, we transform them into probabilities, making them suitable inputs for `nn.BCELoss`. \n",
    "\n",
    "Let's update `num_classes` to 1 so that it is compatible with `nn.BCELoss` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "67ff2ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4096, out_features=1, bias=False)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 1\n",
    "model_4bit.lm_head = torch.nn.Linear(in_features=model_4bit.get_input_embeddings().embedding_dim, out_features=num_classes, bias=False)\n",
    "model_4bit.lm_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b065cef7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralSdpaAttention(\n",
       "          (q_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.01, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (k_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.01, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (v_proj): lora.Linear4bit(\n",
       "            (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "            (lora_dropout): ModuleDict(\n",
       "              (default): Dropout(p=0.01, inplace=False)\n",
       "            )\n",
       "            (lora_A): ModuleDict(\n",
       "              (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "            )\n",
       "            (lora_B): ModuleDict(\n",
       "              (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "            )\n",
       "            (lora_embedding_A): ParameterDict()\n",
       "            (lora_embedding_B): ParameterDict()\n",
       "          )\n",
       "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): MistralRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm()\n",
       "        (post_attention_layernorm): MistralRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=1, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea5948",
   "metadata": {},
   "source": [
    "#### 4. Apply LoRA to reduce memory footprint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "a59a6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pre-processing to prepare model for training\n",
    "https://huggingface.co/docs/peft/v0.11.0/en/package_reference/peft_model#peft.prepare_model_for_kbit_training\n",
    "'''\n",
    "\n",
    "from peft import prepare_model_for_kbit_training\n",
    "model_4bit.gradient_checkpointing_enable()\n",
    "\n",
    "#model_4bit.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\":False})\n",
    "model_4bit = prepare_model_for_kbit_training(model_4bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "08a27323",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For guidelines / general rule of thumb on setting `r` and `lora_alpha`: \n",
    "A good heuristic is setting alpha at twice the rank's value. \n",
    "\n",
    "Reference: https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms (FT w/ LoRA)\n",
    "\"\"\"\n",
    "\n",
    "config = LoraConfig(\n",
    "                        r=32, # Defines the size of the low-rank matrices.\n",
    "                        lora_alpha=64, # Scaling factor for the low-rank matrices. Specifies which parts of the transformer layers to apply LoRA.\n",
    "                        lora_dropout=0.01, # Dropout rate for the LoRA layers\n",
    "                        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\"], # update attention block with LoRA\n",
    "                        bias=\"none\", # Whether to include biases in the LoRA layers\n",
    "                        task_type=\"CAUSAL_LM\", # Indicates the type of task for fine-tuning, in this case, Causal Language Modeling.\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42793f4",
   "metadata": {},
   "source": [
    "`QLoRA` compute-memory Trade-offs: One can save ~33% of GPU memory when using QLoRA. However, this comes at a 39% increased training runtime caused by the additional quantization and dequantization of the pretrained model weights in QLoRA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "32220bd5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): MistralForCausalLM(\n",
       "      (model): MistralModel(\n",
       "        (embed_tokens): Embedding(32000, 4096)\n",
       "        (layers): ModuleList(\n",
       "          (0-31): 32 x MistralDecoderLayer(\n",
       "            (self_attn): MistralSdpaAttention(\n",
       "              (q_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.01, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (k_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.01, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (v_proj): lora.Linear4bit(\n",
       "                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.01, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "              (rotary_emb): MistralRotaryEmbedding()\n",
       "            )\n",
       "            (mlp): MistralMLP(\n",
       "              (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "              (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "              (act_fn): SiLU()\n",
       "            )\n",
       "            (input_layernorm): MistralRMSNorm()\n",
       "            (post_attention_layernorm): MistralRMSNorm()\n",
       "          )\n",
       "        )\n",
       "        (norm): MistralRMSNorm()\n",
       "      )\n",
       "      (lm_head): Linear(in_features=4096, out_features=1, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model = get_peft_model(model_4bit, config)\n",
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "30084a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 18,874,368 || all params: 7,129,538,560 || trainable%: 0.2647\n"
     ]
    }
   ],
   "source": [
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4a525",
   "metadata": {},
   "source": [
    "Notice, the drop in % of trainable parameters from `13.07%` to `0.26%`. `LoRa` allows you to fine-tune large language models using a much smaller set of training parameters while preserving the performance levels typically achieved through full fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b625b1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move the PEFT model to the device\n",
    "peft_model = peft_model.to(device)\n",
    "peft_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "648a4f3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vocab_size': 32000,\n",
       " 'max_position_embeddings': 32768,\n",
       " 'hidden_size': 4096,\n",
       " 'intermediate_size': 14336,\n",
       " 'num_hidden_layers': 32,\n",
       " 'num_attention_heads': 32,\n",
       " 'sliding_window': 4096,\n",
       " 'num_key_value_heads': 8,\n",
       " 'hidden_act': 'silu',\n",
       " 'initializer_range': 0.02,\n",
       " 'rms_norm_eps': 1e-05,\n",
       " 'use_cache': True,\n",
       " 'rope_theta': 10000.0,\n",
       " 'attention_dropout': 0.0,\n",
       " 'return_dict': True,\n",
       " 'output_hidden_states': False,\n",
       " 'output_attentions': False,\n",
       " 'torchscript': False,\n",
       " 'torch_dtype': torch.bfloat16,\n",
       " 'use_bfloat16': False,\n",
       " 'tf_legacy_loss': False,\n",
       " 'pruned_heads': {},\n",
       " 'tie_word_embeddings': False,\n",
       " 'chunk_size_feed_forward': 0,\n",
       " 'is_encoder_decoder': False,\n",
       " 'is_decoder': False,\n",
       " 'cross_attention_hidden_size': None,\n",
       " 'add_cross_attention': False,\n",
       " 'tie_encoder_decoder': False,\n",
       " 'max_length': 20,\n",
       " 'min_length': 0,\n",
       " 'do_sample': False,\n",
       " 'early_stopping': False,\n",
       " 'num_beams': 1,\n",
       " 'num_beam_groups': 1,\n",
       " 'diversity_penalty': 0.0,\n",
       " 'temperature': 1.0,\n",
       " 'top_k': 50,\n",
       " 'top_p': 1.0,\n",
       " 'typical_p': 1.0,\n",
       " 'repetition_penalty': 1.0,\n",
       " 'length_penalty': 1.0,\n",
       " 'no_repeat_ngram_size': 0,\n",
       " 'encoder_no_repeat_ngram_size': 0,\n",
       " 'bad_words_ids': None,\n",
       " 'num_return_sequences': 1,\n",
       " 'output_scores': False,\n",
       " 'return_dict_in_generate': False,\n",
       " 'forced_bos_token_id': None,\n",
       " 'forced_eos_token_id': None,\n",
       " 'remove_invalid_values': False,\n",
       " 'exponential_decay_length_penalty': None,\n",
       " 'suppress_tokens': None,\n",
       " 'begin_suppress_tokens': None,\n",
       " 'architectures': ['MistralForCausalLM'],\n",
       " 'finetuning_task': None,\n",
       " 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'},\n",
       " 'label2id': {'LABEL_0': 0, 'LABEL_1': 1},\n",
       " 'tokenizer_class': None,\n",
       " 'prefix': None,\n",
       " 'bos_token_id': 1,\n",
       " 'pad_token_id': None,\n",
       " 'eos_token_id': 2,\n",
       " 'sep_token_id': None,\n",
       " 'decoder_start_token_id': None,\n",
       " 'task_specific_params': None,\n",
       " 'problem_type': None,\n",
       " '_name_or_path': 'mistralai/Mistral-7B-v0.1',\n",
       " '_commit_hash': '26bca36bde8333b5d7f72e9ed20ccda6a618af24',\n",
       " '_attn_implementation_internal': 'sdpa',\n",
       " 'transformers_version': '4.34.0.dev0',\n",
       " 'model_type': 'mistral',\n",
       " 'quantization_config': BitsAndBytesConfig {\n",
       "   \"_load_in_4bit\": true,\n",
       "   \"_load_in_8bit\": false,\n",
       "   \"bnb_4bit_compute_dtype\": \"bfloat16\",\n",
       "   \"bnb_4bit_quant_storage\": \"bfloat16\",\n",
       "   \"bnb_4bit_quant_type\": \"nf4\",\n",
       "   \"bnb_4bit_use_double_quant\": true,\n",
       "   \"llm_int8_enable_fp32_cpu_offload\": false,\n",
       "   \"llm_int8_has_fp16_weight\": false,\n",
       "   \"llm_int8_skip_modules\": null,\n",
       "   \"llm_int8_threshold\": 6.0,\n",
       "   \"load_in_4bit\": true,\n",
       "   \"load_in_8bit\": false,\n",
       "   \"quant_method\": \"bitsandbytes\"\n",
       " },\n",
       " '_pre_quantization_dtype': torch.float16}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.config.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e23cacd",
   "metadata": {},
   "source": [
    "#### 5. Let's test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0ead9bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 11385, 28747, 12450,   434, 25130]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "inputs = tokenizer(\"Less: Eletricity\", return_tensors=\"pt\").to(0)\n",
    "\n",
    "# Convert input tensors to the dtype expected by the model\n",
    "#inputs = {key: tensor.to(torch.float32) for key, tensor in inputs.items()}\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "aa765512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: torch.int64\n",
      "attention_mask: torch.int64\n"
     ]
    }
   ],
   "source": [
    "for key, tensor in inputs.items():\n",
    "    print(f\"{key}: {tensor.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c2f7cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs['input_ids'] = inputs['input_ids'].to(device)\n",
    "#inputs['input_ids'].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bf5422b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputs['attention_mask'] = inputs['attention_mask'].to(device)\n",
    "#inputs['attention_mask'].device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1f3538fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check device: cuda\n",
    "peft_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c8192fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': device(type='cuda', index=0)}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.hf_device_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cf689ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.lm_head.weight.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "84244229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " torch.Size([1, 6, 1])\n",
      "Outputs Logits:\n",
      " tensor([[[-0.0126],\n",
      "         [-4.3610],\n",
      "         [-3.1300],\n",
      "         [-8.8063],\n",
      "         [-6.1398],\n",
      "         [-3.6898]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): # No gradients accumulation during inference\n",
    "    outputs = peft_model(**inputs)\n",
    "\n",
    "print(\"Outputs:\\n\", outputs.logits.shape)\n",
    "print(\"Outputs Logits:\\n\", outputs.logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8862b196",
   "metadata": {},
   "source": [
    "shape indicates: \n",
    "\n",
    "1. Batch Size (1)\n",
    "2. Sequence Length: # tokens\n",
    "3. Binary classification, 2 as the output. \n",
    "\n",
    "In this modified output layer, the model is not predicting the next token in the sequence as it would in language modeling but rather classifying each token in the input sequence into one of two classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e0845093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.6898]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs.logits[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f0001e",
   "metadata": {},
   "source": [
    "Convert the outputs (logits) into probability scores via the `sigmoid` function and then obtain the index position of the largest probability value via the `argmax` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "11ae5459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0244]], device='cuda:0')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.sigmoid(outputs.logits[:, -1, :])\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "23e0be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(probs):\n",
    "    \n",
    "    # single tensor\n",
    "    \n",
    "    if probs.shape[0] == 1:\n",
    "    \n",
    "        # sigmoid probs represents the probability of belonging to 1\n",
    "        if probs.item() > 0.5:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # multiple tensor - batch\n",
    "    if probs.shape[0] > 1:\n",
    "        \n",
    "        preds = (probs > 0.5).float()\n",
    "        return preds.squeeze()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d392f034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 0\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = get_label(probs)\n",
    "print(f\"Class label: {predicted_labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58690204",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/kevalshah90/token-classification-fine-tuning/blob/main/class.png?raw=1\" width=800px height=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff77747",
   "metadata": {},
   "source": [
    "#### 6. Classification accuracy without Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1a6b8c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "input batch: tensor([[    1, 11385, 28747,  5062,   824, 13887,  5062,   824, 13887, 19026,\n",
      "           346,  5836,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 16157,  1218,   560,  4215, 28747,  8632, 12184,\n",
      "           303, 28716,   551,  8632,   567,   318,   889,   263,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  3357,   992,  9319, 28713,   475,  8034,   387,\n",
      "          2364,  6193,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286,  2693,  1998,  1574,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 16157,  1218,   560,  4215, 28747,   367,   374,\n",
      "           367,   374, 10336,  4615,   274,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  4120,   288,  8105,  9944,  4120,   288,   567,\n",
      "          7721,   465,  9531,   288,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  5299,  5299,   387,  4914, 10705,   288,  4615,\n",
      "           274,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 20460,  1992,  1129,   401,  2443,  1325,  1434,\n",
      "          1640,  4615,   274,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  7960, 22563, 14093,   274, 12860, 13059, 14093,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747,   351,  8286, 28723,  5299,   560,  4215, 21297,\n",
      "          4860, 18834,   560,  4215,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 17053, 21831,   333,  1339,  2378,   734,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,   367,   374, 10336,  1529, 14615,  1028,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286,   351,  8286,   560,  4215,   387, 11819,   440,  4615,\n",
      "           274,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 23948,   689,   926,   274, 22010,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 10711, 27940,  2693,  1998,  1574,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 10711, 27940,   451,  6512,   962,  2043,  2693,  1998,  1574,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 16157,  1218,   560,  4215, 28747,  5299,  1992,\n",
      "          1129,  2494,   270,   401,  2443, 13830,  1232,   689,  2010,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747,   351,  8286, 28723,  5299,   560,  4215,   330,\n",
      "          2129,   472,   401,  2443,   387,  4324,  6072,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9734, 10562, 28707, 11385, 28747, 24551, 12018,\n",
      "         28733,  3922, 28713,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  1325,   964,   594,  8337,   614,  1325,   964,\n",
      "           296,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286,   365,  1841,  4562, 12656,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8650, 16790,  4839,  7838,  4615,   274, 28748,\n",
      "          1209,   926,   274,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  5299,  4902,  4838,  9764,   380, 20370,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 18857, 25949,   393, 14295, 28748,  9489,  7198,\n",
      "          5836,  4615,   274,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  4120,   288,  8105,  9944,  4120,   288, 19409,\n",
      "          3357,   992,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2]])\n",
      "target labels: tensor([0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
      "        0])\n",
      "1\n",
      "input batch: tensor([[    1, 11230, 28747,   351,  8286, 28723,  5299,   560,  4215, 20059,\n",
      "           560,  4215,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 11919,   288,   304, 14421,   279,  4615,   274,\n",
      "         11919,   288,   567,  5299,  8074,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 28128,   292,   643,   304,   550,  2570,   550,\n",
      "          2570, 13253,   560,  4215,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 10711,  9187, 28733, 28754,  7540,   560,  4215,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747,   351,  8286, 28723,  5299,   560,  4215,  5299,\n",
      "           560,  4215,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  5062,   824, 13887,   334,  2074, 28733,  5062,\n",
      "          8951,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8650, 28725,  8871, 28725,  8560,   935,  1046,\n",
      "         11385, 28747,  9187,  4375, 24529,   935,  1046,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 13332,  8406,  1483,  8406,  1483, 28733,   384,\n",
      "          1242,  1193, 28748,  4919,   507, 28713, 14510,   288,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8105,  9944,  4902,   628, 25949,  6320,  1079,\n",
      "          4902,  4838,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 16157,  1218,   560,  4215, 28747,  5299,  1992,\n",
      "          1129,  2494,   270,   401,  2443, 13830,  1232,   689,  2010,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1,  2280,  4950,  1799,  1298, 18931,  1726,   286,  5078, 28719,\n",
      "          1623,  4615,   274,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 18163, 18163,  1366,  2371, 28713,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9769,  8643,  8474,   465,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 10764,  2235,  4615,   274, 10764,  2235,  4615,\n",
      "           274,   325,  3514,   555, 15102, 28731,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1,   420,  1556, 10650,  2256,   399,   308, 11643,   399,   308,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 17053, 21831,   333,  1339,   330,  5569,  1124,\n",
      "           452,  4609,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 10711,   320,  2185,  1086, 16897,   399,  2431,  1086,  2693,\n",
      "          1998,  1574,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 12482,  4615,   274, 12482,   401,  2443,  1325,\n",
      "           964,   296,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  1319,  1029,  4561,  9395,   351,  8286, 28723,\n",
      "         12178, 28726,   789,  4561,  9395,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  3357,   992,  9319, 28713,  2364,  6193,   387,\n",
      "         10757, 14488,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 10764,  2235,  4615,   274,  1337,   555, 10764,\n",
      "          2235,   401,  2443,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  5299, 21644,  8074,  9513, 16455,  4615,   274,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 16157,  1218,   560,  4215, 28747,   367,   374,\n",
      "           367,   374, 10336,  4615,   274,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,   382, 28790,  1645,  8105,  9944,   382, 28790,\n",
      "          1645,  8931,  7631,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  3357,   992,  9319, 28713,   475,  8034,   387,\n",
      "          3592,  8734, 28709,  8931,  7631,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2]])\n",
      "target labels: tensor([1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0])\n",
      "2\n",
      "input batch: tensor([[    1, 24286,  5299,   560,  4215,   325, 20548,   336,  7929, 28737,\n",
      "         28731,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1,   420,  1556, 10650,  2256,   399,   308,   399,  7540,   560,\n",
      "          4215,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286,   365,  1841,  4562, 12656,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 17439, 17439,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747,   351,  8286, 28723,  5299,   560,  4215, 17058,\n",
      "          4615,   274,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 10764,  2235,  4615,   274,  1298, 18931,  1726,\n",
      "           286, 22010,   567, 16081,  8074,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 20459,   472,  9531,   288,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747,  6728,  9187,  6360,   915,   522,  6728,   401,\n",
      "          2443,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1,  2280,  4950,  1799,  6583, 16790,  1058,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  2319,   304, 17627,  1046,  8851,  4839, 28748,\n",
      "         10199,  1046,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 12482,  4615,   274, 12482,  4615,   274,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 12511,  1682, 10001, 14578,  6583, 16790,  1058,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9466,  4615,   274,  9466,   401,  2443,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 20460,  1992,  1129,   401,  2443, 23952,   425,\n",
      "           628,  8074,  7347,   387,   560,  4215,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8650, 28725,  8871, 28725,  8560,   935,  1046,\n",
      "          9187,  4375, 24529,   935,  1046,   325,  6810,   935,  1046,   387,\n",
      "          1366,  2371, 28731,     2,     2],\n",
      "        [    1, 11385, 28747,  8650, 16790,  4839,  2929, 16199,  1298,   321,\n",
      "          7945,   331,  1339,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9260,  1584, 14093,   274,   567, 22710,  1046,\n",
      "          9260,  1584, 14093,   274,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286,   418,   832, 24500,   962,  2043,  4175, 28753,  7592,\n",
      "         28735,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286,   418,   832, 28733, 24500,   962,  2043,  4175, 28753,\n",
      "          7592, 28735,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8650, 28725,  8871, 28725,  8560,   935,  1046,\n",
      "          9187,  4375, 24529,   935,  1046,   325,  6810,   935,  1046,   387,\n",
      "          1366,  2371, 28731,     2,     2],\n",
      "        [    1, 11385, 28747,   318,   889,   263,   318,   889,   263,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9769,  9769,  5836,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8650, 16790,  4839,   935,   267, 26145,  4360,\n",
      "           367,  1826,  2018,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8500,  6912,   304,  3008,  5091,  5299,  5235,\n",
      "          1536,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,   330,  2129,  1218,   475,  8034,   387, 13311,\n",
      "          4120,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2]])\n",
      "target labels: tensor([0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
      "        0])\n",
      "3\n",
      "input batch: tensor([[    1,  2280,  4950,  1799, 16545,   263, 28748,  3261, 16529, 16081,\n",
      "          4615,   274,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 11530, 10764,  7809,  1962, 28713, 19026,   298,\n",
      "         19026,   401,  2443,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  5299, 21644,  8074, 13059,  9513,   386,  1308,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 12511,  1682, 10001,   560, 14199,  9466,   732,\n",
      "          2522,  4800,  6583,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 23948,   689,   926,   274, 22010,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 12511,  1682, 10001, 20466,  6583,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9769,  8643, 28748, 21329, 19412,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9260,  1584, 14093,   274,   567, 22710,  1046,\n",
      "         12195, 22710,  1046,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  1325,   964,   594,  1325,   964,   594,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  1337,  3706, 23393,  4902,   628,  1337,  3706,\n",
      "         23393,  5235,  1536,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  5062,   824, 13887,   367,  1089,   732,  8703,\n",
      "           399, 28800, 28755,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9260,  1584, 14093,   274,   567, 22710,  1046,\n",
      "          1091,  4963,   387,  9260,  1584, 14093,   274,   567, 22710,  1046,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 10711,   320,  2185,  1086, 16897,  2693,  1998,  1574,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8650, 16790,  4839,  9207,  6690,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 10711, 16897,  2693,  1998,  1574,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8650, 16790,  4839,  9207,  6690,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  5062,   824, 13887,  1298, 17140,  1641,  1549,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 21644,  8105,  9944,   475,  8034,   387, 22278,\n",
      "         28748, 28758,  3226,  9319,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  2597,   973,   304, 20214, 28705, 28740, 28734,\n",
      "         28774, 28774, 28418,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286, 16897,  7497, 24298,  4515, 28790,  1020, 23873,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 22010,  4615,   274, 16545,   263,   399,   308,\n",
      "           404, 22010, 11469,  2437,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  3357,   992,  9319, 28713, 14578,   567, 20754,\n",
      "           466, 11548,   560, 16917,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747,   334,  2854,   689,   926,   274, 12184,   303,\n",
      "         28716,   551,  8862,  6583,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286,  5269,   560,  4215,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 14510,   288,  4615,   274, 15819,   715,   823,\n",
      "          2364,  6193, 28733, 28743, 20803,   567,  3357,  3379,     2,     2,\n",
      "             2,     2,     2,     2,     2]])\n",
      "target labels: tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
      "        0])\n",
      "4\n",
      "input batch: tensor([[    1, 11230, 28747,   351,  8286, 28723,  5299,   560,  4215, 20059,\n",
      "           560,  4215,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8650, 28725,  8871, 28725,  8560,   935,  1046,\n",
      "          8871, 13332,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1,  2280,  4950,  1799,  2929, 16199, 13332,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747,   351,  8286, 28723,  5299,   560,  4215,  8246,\n",
      "          9466,  1298,   321,  7945,   331,   466,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9769,   475,  8034,   387,   401,  2119, 28748,\n",
      "         28777,  1002, 28748, 28754,   614,   742, 28748,   718,  3379,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  3357,   992,  9319, 28713, 28128,   292,   643,\n",
      "         14463,  3357,  3379,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  8105,  9944,  4902,   628,  8105,  9944,  4902,\n",
      "          4838,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 28128,   292,   643,   304,   550,  2570, 28128,\n",
      "           292,   643,   560,  4215,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1,  2280,  4950,  1799, 20059,   560,  4215,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  1641, 27010,  1641, 27010,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,   367,   374, 10336,  1529, 14615,  1028,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,   330,  2129,  1218, 23702,  8931,  7631,   567,\n",
      "          3357,  3379,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286, 10711,  6692,  1077,   560,  4215,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  9769,   393,  7712,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1,  2280,  4950,  1799,  1298, 18931,  1726,   286, 17439,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 12482,  4615,   274, 12482,  4615,   274,     2,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747,  8474,  1291,  1298,   321,  7945,   331,   466,\n",
      "          8474,  1291,   387, 28743,  5882,   299,  1298,  2912,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747, 21644,  8105,  9944,  1091,  4963,   387,  8105,\n",
      "          9944,   567, 28646,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 23948,   689,   926,   274, 23948,   401,  2443,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 24286,  5299,   560,  4215,   567, 19026,   346,   689,   926,\n",
      "           274,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 16157,  1218,   560,  4215, 28747,  8632,  1298,\n",
      "         18931,  1726,   286,  8632,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 10764,  2235,  4615,   274, 24969, 13332,   401,\n",
      "          2443,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  5062,   824, 13887,   475,  8034,   387,  2985,\n",
      "           426,   465,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11230, 28747, 20460,  1992,  1129,   401,  2443, 13663, 28733,\n",
      "           657,   401,  2443,  1325,   964,   296,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2],\n",
      "        [    1, 11385, 28747,  3357,   992,  9319, 28713, 23702,  3357,   992,\n",
      "             2,     2,     2,     2,     2,     2,     2,     2,     2,     2,\n",
      "             2,     2,     2,     2,     2]])\n",
      "target labels: tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
      "        0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "for i, (input_batch, target_batch) in enumerate(train_loader):\n",
    "    \n",
    "    print(i)\n",
    "    print('input batch:', input_batch) \n",
    "    print('target labels:', target_batch)\n",
    "    \n",
    "    if i == 4:\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bfe713b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy(data_loader, model, device):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    correct_preds, num_examples = 0, 0\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        \n",
    "        input_batch, target_labels = input_batch.to(device), target_batch.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_batch)\n",
    "        \n",
    "        \"\"\"\n",
    "        Convert raw logits to a probability distribution with softmax\n",
    "        \n",
    "        `outputs.logits[:, -1, :]`: Apply sigmoid to last token in each sequence within the batch\n",
    "        `dim=-1`: Apply along a specific dimension. For classification, range [0,1] \n",
    "        \"\"\"\n",
    "        probs = torch.sigmoid(outputs.logits[:, -1, :])\n",
    "\n",
    "        \"\"\"\n",
    "        Locate index with highest probability value using argmax if using softmax\n",
    "        \"\"\"\n",
    "        predicted_labels = get_label(probs)\n",
    "        \n",
    "        num_examples += input_batch.size(0)\n",
    "        \n",
    "        correct_preds += torch.eq(predicted_labels, target_labels).sum().item()\n",
    "            \n",
    "        if i == 5:\n",
    "            break;\n",
    "            \n",
    "    print('num examples', num_examples)\n",
    "    print('correct preds', correct_preds)\n",
    "    \n",
    "    return round(correct_preds / num_examples,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "03e5b5b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num examples 150\n",
      "correct preds 77\n",
      "Training accuracy: 51.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num examples 150\n",
      "correct preds 75\n",
      "Test accuracy: 50.00%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = calc_accuracy(train_loader, peft_model, device)\n",
    "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
    "test_accuracy = calc_accuracy(test_loader, peft_model, device)\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74133ac2",
   "metadata": {},
   "source": [
    "### 7. Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7453ff",
   "metadata": {},
   "source": [
    "Define a custom class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "97076764",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryClassification(nn.Module):\n",
    "    \n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        #self.dropout = nn.Dropout(0.05)\n",
    "        #self.classifier = nn.Linear(hidden_size, 1)\n",
    "        #self.relu = nn.ReLU()\n",
    "        #self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.base_model(x)\n",
    "        #dropout_output = self.dropout(outputs.logits[:, -1, :])\n",
    "        #relu_output = self.relu(dropout_output[:, -1, :])\n",
    "        \"\"\"\n",
    "        Apply sigmoid to logits to get probabilities\n",
    "        sigmoid(x) = 1 / (1 + exp(-x))\n",
    "        \"\"\"\n",
    "        #probs = self.sigmoid(relu_output)  \n",
    "\n",
    "        #print('forward probs', probs)\n",
    "        return outputs.logits[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "88534197",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassification(\n",
       "  (base_model): PeftModelForCausalLM(\n",
       "    (base_model): LoraModel(\n",
       "      (model): MistralForCausalLM(\n",
       "        (model): MistralModel(\n",
       "          (embed_tokens): Embedding(32000, 4096)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x MistralDecoderLayer(\n",
       "              (self_attn): MistralSdpaAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (rotary_emb): MistralRotaryEmbedding()\n",
       "              )\n",
       "              (mlp): MistralMLP(\n",
       "                (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (act_fn): SiLU()\n",
       "              )\n",
       "              (input_layernorm): MistralRMSNorm()\n",
       "              (post_attention_layernorm): MistralRMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (norm): MistralRMSNorm()\n",
       "        )\n",
       "        (lm_head): Linear(in_features=4096, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the custom BinaryClassificationHead class\n",
    "model_init = BinaryClassification(peft_model)\n",
    "model_init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1902a466",
   "metadata": {},
   "source": [
    "Loss function and optimizer\n",
    "\n",
    "- optimizer:\n",
    "\n",
    "`learning rate` controls the step size at each iteration while moving toward a minimum of the loss function. \n",
    "\n",
    "`weight decay` is (L2 penalty). Adds a small penalty for larger weights, which can help prevent overfitting\n",
    "\n",
    "- Learning Rate Scheduler:\n",
    "\n",
    "`ReduceLROnPlateau` is used to reduce the learning rate when the loss has stopped improving. \n",
    "\n",
    "`factor=0.1` means the learning rate will be reduced by a factor of 10. \n",
    "\n",
    "`patience=1` means the scheduler will wait for 1 epochs before reducing the learning rate if there is no improvement.\n",
    "\n",
    "- In `BCELoss()` we pass the probabilities directly. The `0.5` threshold is only required for converting the probabilities into class labels when you want to calculate the accuracy and return the predictions.\n",
    "\n",
    "  The `BCEWithLogitsLoss()` (Binary Cross Entropy with Logits Loss) function combines a Sigmoid layer and the BCELoss in one single class. This version is more numerically stable than using a plain Sigmoid followed by a BCELoss for several reasons:\n",
    "  \n",
    "   - It uses the log-sum-exp trick for numerical stability.\n",
    "   - It combines the operations internally which can be optimized by the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6e6e7966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = torch.nn.BCELoss()\n",
    "\n",
    "\"\"\"\n",
    "Given that we observe vanishing gradient problem with sigmoid; let's remove sigmoid activation and use BCEWithLogitsLoss() which can be numerically more stable.\n",
    "\"\"\"\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = torch.optim.AdamW(model_init.parameters(), lr=0.0001, eps=1e-08)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d2dc22bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(model, input_batch, target_batch):\n",
    "    \n",
    "    output = model(input_batch)\n",
    "    \n",
    "    # Reshape target to match the shape of probs\n",
    "    target_batch = target_batch.unsqueeze(1)\n",
    "    \n",
    "    if output.shape != target_batch.shape:\n",
    "        print('model output shape', output.shape)\n",
    "        print('target labels shape', target_batch.shape)\n",
    "        raise Exception(\"Shape mismatch between input logits and target label\")\n",
    "            \n",
    "    # Logits of last output token\n",
    "    loss = criterion(output, target_batch)\n",
    "    \n",
    "    return loss, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678d3792",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6a18fef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "def validate(model, data_loader):\n",
    "    \n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    num_examples = 0\n",
    "    total_val_loss = 0\n",
    "    \n",
    "    with torch.no_grad():  # No need to track gradients during validation\n",
    "        for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "            input_batch, target_labels = input_batch.to(device), target_batch.to(device)\n",
    "            \n",
    "            print('iteration {}'.format(i))\n",
    "            \n",
    "            # calculate loss\n",
    "            val_loss, output = calc_loss_batch(model, input_batch, target_labels.float())\n",
    "            # Record loss per batch\n",
    "            total_val_loss += val_loss.item()\n",
    "            val_losses.append(val_loss)\n",
    "\n",
    "            if i%50==0:\n",
    "                print(f'iteration: {i}, validation loss:  {val_loss.item()}')\n",
    "            \n",
    "            # Calculate Accuracy\n",
    "            predicted_labels = get_label(output)\n",
    "            correct_preds += torch.eq(predicted_labels, target_labels).sum().item()\n",
    "            num_examples += input_batch.size(0)\n",
    "    \n",
    "    val_accuracy = correct_preds / num_examples\n",
    "    \n",
    "    # Record Validation Accuracy per epoch\n",
    "    val_accuracies.append(val_accuracy)\n",
    "    avg_val_loss = total_val_loss / len(data_loader)\n",
    "    \n",
    "    return val_accuracy, avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "1495f40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "train_batch_idx = []\n",
    "train_epochs = []\n",
    "\n",
    "def train(epoch):\n",
    "\n",
    "    # set the model to training mode\n",
    "    model_init.train()\n",
    "    correct_preds = 0\n",
    "    num_examples = 0\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    best_model_path = ''\n",
    "    \n",
    "    for i, (input_batch, target_batch) in enumerate(train_loader):\n",
    "        \n",
    "        input_batch, target_labels = input_batch.to(device), target_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # Reset loss gradients from previous batch\n",
    "        \n",
    "        print('iteration {}'.format(i))\n",
    "        \n",
    "        # calculate loss\n",
    "        loss, output = calc_loss_batch(model_init, input_batch, target_labels.float())\n",
    "\n",
    "        if i%50==0:\n",
    "            print(f'epoch: {epoch}, training loss:  {loss.item()}')\n",
    "\n",
    "        loss.backward() # Backpropogation - calculate loss gradients\n",
    "        \n",
    "        # print gradients\n",
    "#         for name, param in model_init.named_parameters():\n",
    "#             if param.grad is not None:\n",
    "#                 print(f'Gradient for {name}: {param.grad.norm()}')\n",
    "                \n",
    "        # Clip gradients\n",
    "        max_norm = 1\n",
    "        torch.nn.utils.clip_grad_norm_(model_init.parameters(), max_norm)\n",
    "        \n",
    "        # update model weights using loss gradients\n",
    "        optimizer.step() \n",
    "        \n",
    "        # Calculate Accuracy\n",
    "        predicted_labels = get_label(output)\n",
    "        correct_preds += torch.eq(predicted_labels, target_labels).sum().item()\n",
    "        num_examples += input_batch.size(0)\n",
    "        \n",
    "        # Record Training Loss per batch\n",
    "        train_losses.append(loss.item())\n",
    "        train_batch_idx.append(i)\n",
    "\n",
    "        # early stopping\n",
    "        #if i == 2:\n",
    "        #    break;\n",
    "        \n",
    "    # Calculate and Record Accuracy per epoch\n",
    "    train_epochs.append(epoch)\n",
    "    train_accuracy = correct_preds / num_examples\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    avg_train_loss = sum(train_losses)/len(train_loader)\n",
    "    \n",
    "    print(f\"Epoch {epoch} - Avg. Training Loss: {avg_train_loss:.2f}, Training Accuracy: {train_accuracy:.2f}\")\n",
    "        \n",
    "    # Record validation loss and accuracy\n",
    "    val_accuracy, avg_val_loss  = validate(model_init, val_loader)\n",
    "        \n",
    "    print(f\"Epoch {epoch} - Avg. Validation Loss: {avg_val_loss:.2f}, Validation Accuracy: {val_accuracy:.2f}\")\n",
    "    \n",
    "    # Step the scheduler after epoch completion\n",
    "    scheduler.step(loss)\n",
    "        \n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model_init.state_dict(), 'classifier.pth')\n",
    "        print(f\"Saved best model with validation loss: {best_val_loss:.2f}\")\n",
    "    \n",
    "    return model_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a6ddd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, training loss:  0.7561692595481873\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "epoch: 1, training loss:  0.08849111199378967\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "iteration 100\n",
      "epoch: 1, training loss:  0.07008814811706543\n",
      "iteration 101\n",
      "iteration 102\n",
      "iteration 103\n",
      "iteration 104\n",
      "iteration 105\n",
      "iteration 106\n",
      "iteration 107\n",
      "iteration 108\n",
      "iteration 109\n",
      "iteration 110\n",
      "iteration 111\n",
      "iteration 112\n",
      "iteration 113\n",
      "iteration 114\n",
      "iteration 115\n",
      "iteration 116\n",
      "iteration 117\n",
      "iteration 118\n",
      "iteration 119\n",
      "iteration 120\n",
      "iteration 121\n",
      "iteration 122\n",
      "iteration 123\n",
      "iteration 124\n",
      "iteration 125\n",
      "iteration 126\n",
      "iteration 127\n",
      "iteration 128\n",
      "iteration 129\n",
      "iteration 130\n",
      "iteration 131\n",
      "iteration 132\n",
      "iteration 133\n",
      "iteration 134\n",
      "iteration 135\n",
      "iteration 136\n",
      "iteration 137\n",
      "iteration 138\n",
      "iteration 139\n",
      "iteration 140\n",
      "iteration 141\n",
      "iteration 142\n",
      "iteration 143\n",
      "iteration 144\n",
      "iteration 145\n",
      "iteration 146\n",
      "iteration 147\n",
      "iteration 148\n",
      "iteration 149\n",
      "iteration 150\n",
      "epoch: 1, training loss:  0.02106022834777832\n",
      "iteration 151\n",
      "iteration 152\n",
      "iteration 153\n",
      "iteration 154\n",
      "iteration 155\n",
      "iteration 156\n",
      "iteration 157\n",
      "iteration 158\n",
      "iteration 159\n",
      "iteration 160\n",
      "iteration 161\n",
      "iteration 162\n",
      "iteration 163\n",
      "iteration 164\n",
      "iteration 165\n",
      "iteration 166\n",
      "iteration 167\n",
      "iteration 168\n",
      "iteration 169\n",
      "iteration 170\n",
      "iteration 171\n",
      "iteration 172\n",
      "iteration 173\n",
      "iteration 174\n",
      "iteration 175\n",
      "iteration 176\n",
      "iteration 177\n",
      "iteration 178\n",
      "iteration 179\n",
      "Epoch 1 - Avg. Training Loss: 0.17, Training Accuracy: 0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, validation loss:  0.05078840255737305\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "Epoch 1 - Avg. Validation Loss: 0.10, Validation Accuracy: 0.97\n",
      "Saved best model with validation loss: 0.10\n",
      "Epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, training loss:  0.37176313996315\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "epoch: 2, training loss:  8.461477409582585e-05\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "iteration 100\n",
      "epoch: 2, training loss:  3.07658137899125e-06\n",
      "iteration 101\n",
      "iteration 102\n",
      "iteration 103\n",
      "iteration 104\n",
      "iteration 105\n",
      "iteration 106\n",
      "iteration 107\n",
      "iteration 108\n",
      "iteration 109\n",
      "iteration 110\n",
      "iteration 111\n",
      "iteration 112\n",
      "iteration 113\n",
      "iteration 114\n",
      "iteration 115\n",
      "iteration 116\n",
      "iteration 117\n",
      "iteration 118\n",
      "iteration 119\n",
      "iteration 120\n",
      "iteration 121\n",
      "iteration 122\n",
      "iteration 123\n",
      "iteration 124\n",
      "iteration 125\n",
      "iteration 126\n",
      "iteration 127\n",
      "iteration 128\n",
      "iteration 129\n",
      "iteration 130\n",
      "iteration 131\n",
      "iteration 132\n",
      "iteration 133\n",
      "iteration 134\n",
      "iteration 135\n",
      "iteration 136\n",
      "iteration 137\n",
      "iteration 138\n",
      "iteration 139\n",
      "iteration 140\n",
      "iteration 141\n",
      "iteration 142\n",
      "iteration 143\n",
      "iteration 144\n",
      "iteration 145\n",
      "iteration 146\n",
      "iteration 147\n",
      "iteration 148\n",
      "iteration 149\n",
      "iteration 150\n",
      "epoch: 2, training loss:  0.001079533714801073\n",
      "iteration 151\n",
      "iteration 152\n",
      "iteration 153\n",
      "iteration 154\n",
      "iteration 155\n",
      "iteration 156\n",
      "iteration 157\n",
      "iteration 158\n",
      "iteration 159\n",
      "iteration 160\n",
      "iteration 161\n",
      "iteration 162\n",
      "iteration 163\n",
      "iteration 164\n",
      "iteration 165\n",
      "iteration 166\n",
      "iteration 167\n",
      "iteration 168\n",
      "iteration 169\n",
      "iteration 170\n",
      "iteration 171\n",
      "iteration 172\n",
      "iteration 173\n",
      "iteration 174\n",
      "iteration 175\n",
      "iteration 176\n",
      "iteration 177\n",
      "iteration 178\n",
      "iteration 179\n",
      "Epoch 2 - Avg. Training Loss: 0.19, Training Accuracy: 0.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, validation loss:  0.0007924533565528691\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "Epoch 2 - Avg. Validation Loss: 0.01, Validation Accuracy: 1.00\n",
      "Saved best model with validation loss: 0.01\n",
      "Epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3, training loss:  0.00010061990906251594\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "epoch: 3, training loss:  9.706344826554414e-06\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 59\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "iteration 100\n",
      "epoch: 3, training loss:  0.0002218217559857294\n",
      "iteration 101\n",
      "iteration 102\n",
      "iteration 103\n",
      "iteration 104\n",
      "iteration 105\n",
      "iteration 106\n",
      "iteration 107\n",
      "iteration 108\n",
      "iteration 109\n",
      "iteration 110\n",
      "iteration 111\n",
      "iteration 112\n",
      "iteration 113\n",
      "iteration 114\n",
      "iteration 115\n",
      "iteration 116\n",
      "iteration 117\n",
      "iteration 118\n",
      "iteration 119\n",
      "iteration 120\n",
      "iteration 121\n",
      "iteration 122\n",
      "iteration 123\n",
      "iteration 124\n",
      "iteration 125\n",
      "iteration 126\n",
      "iteration 127\n",
      "iteration 128\n",
      "iteration 129\n",
      "iteration 130\n",
      "iteration 131\n",
      "iteration 132\n",
      "iteration 133\n",
      "iteration 134\n",
      "iteration 135\n",
      "iteration 136\n",
      "iteration 137\n",
      "iteration 138\n",
      "iteration 139\n",
      "iteration 140\n",
      "iteration 141\n",
      "iteration 142\n",
      "iteration 143\n",
      "iteration 144\n",
      "iteration 145\n",
      "iteration 146\n",
      "iteration 147\n",
      "iteration 148\n",
      "iteration 149\n",
      "iteration 150\n",
      "epoch: 3, training loss:  0.01752290315926075\n",
      "iteration 151\n",
      "iteration 152\n",
      "iteration 153\n",
      "iteration 154\n",
      "iteration 155\n",
      "iteration 156\n",
      "iteration 157\n",
      "iteration 158\n",
      "iteration 159\n",
      "iteration 160\n",
      "iteration 161\n",
      "iteration 162\n",
      "iteration 163\n",
      "iteration 164\n",
      "iteration 165\n",
      "iteration 166\n",
      "iteration 167\n",
      "iteration 168\n",
      "iteration 169\n",
      "iteration 170\n",
      "iteration 171\n",
      "iteration 172\n",
      "iteration 173\n",
      "iteration 174\n",
      "iteration 175\n",
      "iteration 176\n",
      "iteration 177\n",
      "iteration 178\n",
      "iteration 179\n",
      "Epoch 3 - Avg. Training Loss: 0.21, Training Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, validation loss:  9.77895688265562e-05\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "Epoch 3 - Avg. Validation Loss: 0.02, Validation Accuracy: 0.99\n",
      "Saved best model with validation loss: 0.02\n",
      "Epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, training loss:  4.907637776341289e-05\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "iteration 30\n",
      "iteration 31\n",
      "iteration 32\n",
      "iteration 33\n",
      "iteration 34\n",
      "iteration 35\n",
      "iteration 36\n",
      "iteration 37\n",
      "iteration 38\n",
      "iteration 39\n",
      "iteration 40\n",
      "iteration 41\n",
      "iteration 42\n",
      "iteration 43\n",
      "iteration 44\n",
      "iteration 45\n",
      "iteration 46\n",
      "iteration 47\n",
      "iteration 48\n",
      "iteration 49\n",
      "iteration 50\n",
      "epoch: 4, training loss:  2.00697650143411e-05\n",
      "iteration 51\n",
      "iteration 52\n",
      "iteration 53\n",
      "iteration 54\n",
      "iteration 55\n",
      "iteration 56\n",
      "iteration 57\n",
      "iteration 58\n",
      "iteration 60\n",
      "iteration 61\n",
      "iteration 62\n",
      "iteration 63\n",
      "iteration 64\n",
      "iteration 65\n",
      "iteration 66\n",
      "iteration 67\n",
      "iteration 68\n",
      "iteration 69\n",
      "iteration 70\n",
      "iteration 71\n",
      "iteration 72\n",
      "iteration 73\n",
      "iteration 74\n",
      "iteration 75\n",
      "iteration 76\n",
      "iteration 77\n",
      "iteration 78\n",
      "iteration 79\n",
      "iteration 80\n",
      "iteration 81\n",
      "iteration 82\n",
      "iteration 83\n",
      "iteration 84\n",
      "iteration 85\n",
      "iteration 86\n",
      "iteration 87\n",
      "iteration 88\n",
      "iteration 89\n",
      "iteration 90\n",
      "iteration 91\n",
      "iteration 92\n",
      "iteration 93\n",
      "iteration 94\n",
      "iteration 95\n",
      "iteration 96\n",
      "iteration 97\n",
      "iteration 98\n",
      "iteration 99\n",
      "iteration 100\n",
      "epoch: 4, training loss:  3.924731117876945e-06\n",
      "iteration 101\n",
      "iteration 102\n",
      "iteration 103\n",
      "iteration 104\n",
      "iteration 105\n",
      "iteration 106\n",
      "iteration 107\n",
      "iteration 108\n",
      "iteration 109\n",
      "iteration 110\n",
      "iteration 111\n",
      "iteration 112\n",
      "iteration 113\n",
      "iteration 114\n",
      "iteration 115\n",
      "iteration 116\n",
      "iteration 117\n",
      "iteration 118\n",
      "iteration 119\n",
      "iteration 120\n",
      "iteration 121\n",
      "iteration 122\n",
      "iteration 123\n",
      "iteration 124\n",
      "iteration 125\n",
      "iteration 126\n",
      "iteration 127\n",
      "iteration 128\n",
      "iteration 129\n",
      "iteration 130\n",
      "iteration 131\n",
      "iteration 132\n",
      "iteration 133\n",
      "iteration 134\n",
      "iteration 135\n",
      "iteration 136\n",
      "iteration 137\n",
      "iteration 138\n",
      "iteration 139\n",
      "iteration 140\n",
      "iteration 141\n",
      "iteration 142\n",
      "iteration 143\n",
      "iteration 144\n",
      "iteration 145\n",
      "iteration 146\n",
      "iteration 147\n",
      "iteration 148\n",
      "iteration 149\n",
      "iteration 150\n",
      "epoch: 4, training loss:  5.0784030463546515e-05\n",
      "iteration 151\n",
      "iteration 152\n",
      "iteration 153\n",
      "iteration 154\n",
      "iteration 155\n",
      "iteration 156\n",
      "iteration 157\n",
      "iteration 158\n",
      "iteration 159\n",
      "iteration 160\n",
      "iteration 161\n",
      "iteration 162\n",
      "iteration 163\n",
      "iteration 164\n",
      "iteration 165\n",
      "iteration 166\n",
      "iteration 167\n",
      "iteration 168\n",
      "iteration 169\n",
      "iteration 170\n",
      "iteration 171\n",
      "iteration 172\n",
      "iteration 173\n",
      "iteration 174\n",
      "iteration 175\n",
      "iteration 176\n",
      "iteration 177\n",
      "iteration 178\n",
      "iteration 179\n",
      "Epoch 4 - Avg. Training Loss: 0.23, Training Accuracy: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0, validation loss:  2.3646012778044678e-05\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "Epoch 4 - Avg. Validation Loss: 0.00, Validation Accuracy: 1.00\n",
      "Saved best model with validation loss: 0.00\n",
      "Training completed in 149.21 minutes.\n"
     ]
    }
   ],
   "source": [
    "# Start the Training run\n",
    "start_time = time.time()\n",
    "\n",
    "EPOCHS = 4\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print('Epoch:', epoch)\n",
    "    model = train(epoch)\n",
    "    \n",
    "end_time = time.time()\n",
    "\n",
    "exec_time_mins = (end_time - start_time)/60\n",
    "print(f\"Training completed in {exec_time_mins:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6f364460",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Execution time per epoch 37.30 mins'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Execution time per epoch {exec_time_mins/EPOCHS:.2f} mins\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "553619ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Avg. Training loss: 0.23\n",
      "Overall Avg. Training accuracy: 98.23%\n",
      "Overall Avg. Validation loss: 0.14\n",
      "Overall Avg. Validation accuracy: 99.13%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average loss over all of the batches.\n",
    "avg_train_loss = sum(train_losses) / len(train_loader) \n",
    "avg_val_loss = sum(val_losses) / len(val_loader)\n",
    "\n",
    "avg_train_accuracy = sum(train_accuracies) / EPOCHS\n",
    "avg_val_accuracy = sum(val_accuracies) / EPOCHS\n",
    "\n",
    "print(\"Overall Avg. Training loss: {0:.2f}\".format(avg_train_loss))\n",
    "print(\"Overall Avg. Training accuracy: {:.2f}%\".format(avg_train_accuracy*100))\n",
    "\n",
    "print(\"Overall Avg. Validation loss: {0:.2f}\".format(avg_val_loss))\n",
    "print(\"Overall Avg. Validation accuracy: {:.2f}%\".format(avg_val_accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8398f4",
   "metadata": {},
   "source": [
    "Plot loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4e00aab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(np.array(train_losses), label='Train Loss')\n",
    "# plt.plot(np.array(val_losses), label='Validation Loss')\n",
    "# plt.xlabel('Batch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Loss curves')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da360c3",
   "metadata": {},
   "source": [
    "Evaluate on test data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "38ba2801",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BinaryClassification(\n",
       "  (base_model): PeftModelForCausalLM(\n",
       "    (base_model): LoraModel(\n",
       "      (model): MistralForCausalLM(\n",
       "        (model): MistralModel(\n",
       "          (embed_tokens): Embedding(32000, 4096)\n",
       "          (layers): ModuleList(\n",
       "            (0-31): 32 x MistralDecoderLayer(\n",
       "              (self_attn): MistralSdpaAttention(\n",
       "                (q_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=4096, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (k_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (v_proj): lora.Linear4bit(\n",
       "                  (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.01, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=4096, out_features=32, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=32, out_features=1024, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
       "                (rotary_emb): MistralRotaryEmbedding()\n",
       "              )\n",
       "              (mlp): MistralMLP(\n",
       "                (gate_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (up_proj): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
       "                (down_proj): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
       "                (act_fn): SiLU()\n",
       "              )\n",
       "              (input_layernorm): MistralRMSNorm()\n",
       "              (post_attention_layernorm): MistralRMSNorm()\n",
       "            )\n",
       "          )\n",
       "          (norm): MistralRMSNorm()\n",
       "        )\n",
       "        (lm_head): Linear(in_features=4096, out_features=1, bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.getcwd() + '/classifier.pth'\n",
    "\n",
    "model = BinaryClassification(peft_model)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ecfb5de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n",
      "iteration: 0, validation loss:  9.630246495362371e-06\n",
      "iteration 1\n",
      "iteration 2\n",
      "iteration 3\n",
      "iteration 4\n",
      "iteration 5\n",
      "iteration 6\n",
      "iteration 7\n",
      "iteration 8\n",
      "iteration 9\n",
      "iteration 10\n",
      "iteration 11\n",
      "iteration 12\n",
      "iteration 13\n",
      "iteration 14\n",
      "iteration 15\n",
      "iteration 16\n",
      "iteration 17\n",
      "iteration 18\n",
      "iteration 19\n",
      "iteration 20\n",
      "iteration 21\n",
      "iteration 22\n",
      "iteration 23\n",
      "iteration 24\n",
      "iteration 25\n",
      "iteration 26\n",
      "iteration 27\n",
      "iteration 28\n",
      "iteration 29\n",
      "Avg. test loss: 0.01, Test Accuracy: 99.73%\n"
     ]
    }
   ],
   "source": [
    "test_accuracy, avg_test_loss = validate(model, test_loader)\n",
    "print(f\"Avg. test loss: {avg_test_loss:.2f}, Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10ed228",
   "metadata": {},
   "source": [
    "### Deploy to AWS SageMaker\n",
    "\n",
    "- https://sagemaker-examples.readthedocs.io/en/latest/frameworks/pytorch/get_started_mnist_deploy.html \n",
    "\n",
    "- https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-python-sdk/pytorch_batch_inference/sagemaker_batch_inference_torchserve.ipynb\n",
    "\n",
    "- https://sagemaker.readthedocs.io/en/stable/frameworks/pytorch/using_pytorch.html#deploy-pytorch-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dbd119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.deserializers import JSONDeserialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc4f533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Upload the model to S3\n",
    "def upload_to_s3(bucket_name, model_name):\n",
    "    s3_client = boto3.client('s3')\n",
    "    s3_client.upload_file('model.pth', bucket_name, f'{model_name}/model.pth')\n",
    "    print(f\"Model uploaded to s3://{bucket_name}/{model_name}/model.pth\")\n",
    "\n",
    "# Step 3: Create a SageMaker model and deploy to an endpoint\n",
    "def deploy_to_sagemaker(bucket_name, model_name, role_arn):\n",
    "    sagemaker_session = sagemaker.Session()\n",
    "    \n",
    "    # Create PyTorch model\n",
    "    pytorch_model = PyTorchModel(\n",
    "        model_data=f's3://{bucket_name}/{model_name}/model.pth',\n",
    "        role=role_arn,\n",
    "        entry_point='inference.py',  # create this file\n",
    "        framework_version='1.8.1',  # Adjust as needed\n",
    "        py_version='py3',\n",
    "        predictor_cls=sagemaker.predictor.Predictor,\n",
    "        serializer=JSONSerializer(),\n",
    "        deserializer=JSONDeserializer()\n",
    "    )\n",
    "    \n",
    "    # Deploy the model to an endpoint\n",
    "    predictor = pytorch_model.deploy(\n",
    "        initial_instance_count=1,\n",
    "        instance_type='ml.m5.large',  # Adjust as needed\n",
    "        endpoint_name=f'{model_name}-endpoint'\n",
    "    )\n",
    "    \n",
    "    print(f\"Model deployed to endpoint: {predictor.endpoint_name}\")\n",
    "    return predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    package_model()\n",
    "    \n",
    "    bucket_name = 'your-s3-bucket-name'\n",
    "    model_name = 'your-model-name'\n",
    "    role_arn = 'your-sagemaker-role-arn'\n",
    "    \n",
    "    upload_to_s3(bucket_name, model_name)\n",
    "    predictor = deploy_to_sagemaker(bucket_name, model_name, role_arn)\n",
    "\n",
    "    # Test the endpoint\n",
    "    test_data = {\"input\": [1.0, 2.0, 3.0, 4.0]}  # Adjust based on your model's input\n",
    "    result = predictor.predict(test_data)\n",
    "    print(\"Prediction result:\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097bd28a",
   "metadata": {},
   "source": [
    "**Some notes and observations from Training Loop:**\n",
    "\n",
    "1. \n",
    "\n",
    "- When the `probs tensor` contains all `1s`, it means that the model is predicting the positive class with very high confidence for all the samples in the batch.\n",
    "\n",
    "- In the `BinaryClassification` class, the forward method takes the input `x` and passes it through the `base_model` to obtain the outputs. The `outputs.logits` tensor contains the `unnormalized log probabilities (logits)` for each token in the sequence.\n",
    "\n",
    "- The line `probs = self.sigmoid(outputs.logits[:, -1, :])` applies the `sigmoid` activation function to the logits of the last token in each sequence. The sigmoid function maps the logits to probabilities between `0` and `1`.\n",
    "If probs is all `1s`, it suggests that the model is extremely confident in predicting the positive class for all the samples. \n",
    "\n",
    "This could happen due to several reasons:\n",
    "\n",
    "`Overfitting:` The model may have overfit to the training data, learning to predict the positive class with high confidence for all the samples, even if they don't truly belong to the positive class. Overfitting can occur when the model is too complex relative to the amount of training data or when the training process continues for too long.\n",
    "\n",
    "`Imbalanced dataset:` If the training data is heavily imbalanced, with a significantly higher number of positive samples compared to negative samples, the model may learn to predict the positive class by default. This can lead to high probabilities for the positive class, even for negative samples.\n",
    "\n",
    "`Insufficient regularization:` Regularization techniques, such as dropout or weight decay, help prevent overfitting by introducing noise or constraints during training. If the model lacks proper regularization, it may become overconfident in its predictions.\n",
    "\n",
    "2. \n",
    "\n",
    "`Vanishing gradients problem commonly observed with sigmoid activation`\n",
    "\n",
    "    - The vanishing gradient problem is a significant issue when using the sigmoid activation function in deep neural networks due to the multiplicative nature of backpropagation and the small derivative values of the sigmoid function, especially in the saturated regions. \n",
    "    \n",
    "    - The intuition behind the saturated region is that when the output of the sigmoid function becomes saturated (i.e., remains constant), it means that the input to the sigmoid function is either a large positive or negative value. In such cases, even if the weights are updated, the output of the sigmoid function will remain almost the same, as it is already saturated at either 0 or 1.\n",
    "    \n",
    "    \n",
    "3. \n",
    "\n",
    "`Interpreting gradients`\n",
    "\n",
    "    - Gradient Magnitude: Large gradients (e.g., > 1) might indicate unstable learning or potential exploding gradients. Very small gradients (e.g., < 1e-5) could suggest vanishing gradients or that the model has converged. Moderate, non-zero gradients typically indicate active learning. Gradients should generally be non-zero but not too large (e.g., between 1e-5 and 1).\n",
    "\n",
    "\n",
    "    - Gradient Direction:\n",
    "        - Positive gradients mean the loss increases as the parameter increases.\n",
    "        - Negative gradients mean the loss decreases as the parameter increases.\n",
    "\n",
    "\n",
    "    - Gradient Variability:\n",
    "        - If gradients vary significantly between batches, it might indicate high variance in your data or unstable learning.\n",
    "        - Consistent gradients across batches suggest stable learning.\n",
    "\n",
    "    - LoRA Architecture: LoRA adds small, trainable rank decomposition matrices to the original model layers, typically attention layers. The original model parameters remain frozen, and only these new LoRA parameters are trained.\n",
    "   \n",
    "    - Gradient Flow: Gradients will only flow through the LoRA parameters, not the original model parameters. This means you'll only see non-zero gradients for these new parameters.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a61bddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796a64d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9d8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f294a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bcfac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0c471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62785a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf758d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c921cea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04872604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53aa71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85c14de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16ae362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea413ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5e692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de49a41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc0081",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "020e27c8",
   "metadata": {},
   "source": [
    "While, finetuning only the last layer could also be considered a parameter-efficient finetuning technique,  techniques such as prefix tuning, adapters, and low-rank adaptation, all of which â€œmodifyâ€ multiple layers, namely `attention layers` and `feed-forward` to achieve much better predictive performance (at a low cost).\n",
    "\n",
    "So, we can also make the last transformer block and the final `LayerNorm` module connecting the last transformer block to the output layer trainable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3a8ef8",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/kevalshah90/token-classification-fine-tuning/blob/main/layernorm.png?raw=1\" width=\"500px\" height=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ab813",
   "metadata": {},
   "source": [
    "#### 4. Fine-tuning Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49831a5",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/kevalshah90/token-classification-fine-tuning/blob/main/trainepoch.png?raw=1\" width=\"500px\" height=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de6f7c",
   "metadata": {},
   "source": [
    "Before explaining the loss calculation, let's have a brief look at how the model outputs are turned into class labels\n",
    "\n",
    "<img src=\"https://github.com/kevalshah90/token-classification-fine-tuning/blob/main/loss.png?raw=1\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af167ffb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995da97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99204892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ed1bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8360668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca5e05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c242dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba21a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88480a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1f5d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef2938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e16e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc243aa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8691dd4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c682d973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a55c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d9bfee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dff0825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97ca9d8d",
   "metadata": {},
   "source": [
    "Finally, let's save the model. https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "\n",
    "`torch.save(model.state_dict(), PATH)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f25049b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"classifier.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3662bce",
   "metadata": {},
   "source": [
    "#### 4. SageMaker endpoint / deployment code, Batch inference\n",
    "\n",
    "https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_applying_machine_learning/mixtral_tune_and_deploy/mixtral-8x7b.html \n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker_batch_transform/pytorch_mnist_batch_transform/pytorch-mnist-batch-transform.ipynb\n",
    "\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker_batch_transform/pytorch_mnist_batch_transform/pytorch-mnist-batch-transform.ipynb\n",
    "\n",
    "Instance type: `g4dn.xlarge`, 1 NVIDIA T4 Tensor Core GPU, 4 vCPUs: https://aws.amazon.com/ec2/instance-types/g4/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a048982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sagemaker\n",
    "# from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# # Configure SageMaker session\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# # Define the S3 bucket location for your model artifacts\n",
    "# model_data_dir = sagemaker_session.default_bucket() + \"/model\"\n",
    "\n",
    "# # Upload the trained model to S3\n",
    "# sagemaker.upload_data(path=\"review_classifier.pth\", key_prefix=model_data_dir)\n",
    "\n",
    "# # Define the entry script for model inference\n",
    "# entry_script = \"inference.py\"  # Replace with your actual script name\n",
    "\n",
    "# # Create a PyTorchModel object\n",
    "# model = PyTorchModel(\n",
    "#     image_uri=sagemaker.image_uris.retrieve(framework=\"pytorch\", region=sagemaker_session. boto3_region_name),\n",
    "#     model_data=model_data_dir,\n",
    "#     entry_script=entry_script,\n",
    "#     role=sagemaker.get_execution_role(),\n",
    "#     framework_version=\"py3.8\"  # Replace with your framework version\n",
    "# )\n",
    "\n",
    "# # Deploy the model to a SageMaker endpoint\n",
    "# predictor = model.deploy(initial_instance_count=1, instance_type=\"g4dn.xlarge\")  # Adjust instance type as needed\n",
    "\n",
    "# # Define your batch inference function (replace with your logic)\n",
    "# def predict_on_batch(data):\n",
    "#     # Preprocess your batch data here\n",
    "#     # ...\n",
    "#     response = predictor.predict(data)\n",
    "#     # Postprocess the inference results here\n",
    "#     # ...\n",
    "#     return processed_results\n",
    "\n",
    "# # Example usage\n",
    "# batch_data = # Your batch data for inference\n",
    "# predictions = predict_on_batch(batch_data)\n",
    "\n",
    "# # Print the predictions\n",
    "# print(predictions)\n",
    "\n",
    "# # Delete the endpoint when finished\n",
    "# predictor.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff10c898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50bd0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68625e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcdd867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3f836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657f22c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50dcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712bf32c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264dc285",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356fc097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867fbd7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e71ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409feece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfd073d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8614dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4164987d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9507492",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41b2d48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
